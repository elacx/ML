{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "# general\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from numpy import dot \n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "# lime\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "# advertorch \n",
    "from advertorch.attacks import LinfPGDAttack\n",
    "# cpu / gpu\n",
    "if torch.cuda.is_available():  \n",
    "    device = 'cuda:0'\n",
    "else:  \n",
    "    device = 'cpu'\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain mnist data and process\n",
    "batch_size = 128\n",
    "\n",
    "dataset = MNIST('.', train=True, download=False,transform=transforms.ToTensor())\n",
    "dataset_test = MNIST('.', train=False, download=False,transform=transforms.ToTensor())\n",
    "\n",
    "train1, train2 = random_split(dataset,[30000,30000])#DataLoader(dataset, batch_size=batch_size)\n",
    "data_loader_train1 = DataLoader(train1, batch_size=batch_size)\n",
    "data_loader_train2 = DataLoader(train2, batch_size=batch_size)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch network \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, layers, num_classes=10, net_num=1, dev='cpu'):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.net_num = net_num\n",
    "        self.path = './models/network'+str(self.net_num)+'_'+str(self.layers)+'.pth'\n",
    "        self.dev = dev\n",
    "        # layers\n",
    "        self.fc_linears = nn.ModuleList()\n",
    "        for i in range(len(self.layers)-1):\n",
    "            self.fc_linears.append(nn.Sequential(nn.Linear(in_features=self.layers[i], out_features=self.layers[i+1]),nn.BatchNorm1d(self.layers[i+1]),nn.ReLU()))\n",
    "        self.f_final = nn.Linear(self.layers[-1],num_classes)\n",
    "        self.fc_linears.to(dev)\n",
    "        self.f_final.to(dev)\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        for l in self.fc_linears:\n",
    "            x = l(x)\n",
    "        x = softmax(self.f_final(x))\n",
    "        return x\n",
    "    \n",
    "    def train(self, train_data, loss_fn=nn.CrossEntropyLoss(), n_epochs=50, save=True):\n",
    "        for epoch in range(n_epochs):\n",
    "            for data,target in train_data:\n",
    "                data, target = data.reshape(data.shape[0],28*28).to(self.dev),target.to(self.dev)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.forward(data)\n",
    "                loss = loss_fn(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            if (epoch+1)%10 == 0:\n",
    "                print('epoch/epochs: '+str(epoch+1)+'/'+str(n_epochs))\n",
    "                print('accuracy: ', round((torch.argmax(output,dim=1) == target).sum().item()/len(target)*100.,5), '%')\n",
    "                print('------------------------------')\n",
    "        if save:\n",
    "            torch.save(self.state_dict(), self.path)\n",
    "            print('saved to '+self.path+'!')\n",
    "            \n",
    "    def accuracy(self, test_data):\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        for x,y in test_data:\n",
    "            x,y = x.reshape(x.shape[0],28*28).to(self.dev),y.to(self.dev)\n",
    "            output = self.forward(x)\n",
    "            correct += (torch.argmax(output,dim=1) == y).sum().item()\n",
    "            total += len(y)\n",
    "        print('model accuracy: ',round((correct/total)*100,5),'%')\n",
    "        \n",
    "    def load(self):\n",
    "        self.load_state_dict(torch.load(self.path))\n",
    "        print('model loaded from ', self.path, '!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "ARCHITECTURE  0  | MODEL  0\n",
      "epoch/epochs: 10/100\n",
      "accuracy:  95.83333 %\n",
      "------------------------------\n",
      "epoch/epochs: 20/100\n",
      "accuracy:  97.91667 %\n",
      "------------------------------\n",
      "epoch/epochs: 30/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 40/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 50/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 60/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 70/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 80/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 90/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 100/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "saved to ./models/network0_[784, 500, 100].pth!\n",
      "model accuracy:  97.43 %\n",
      "------------------------------------------------------------\n",
      "ARCHITECTURE  0  | MODEL  1\n",
      "epoch/epochs: 10/100\n",
      "accuracy:  93.75 %\n",
      "------------------------------\n",
      "epoch/epochs: 20/100\n",
      "accuracy:  95.83333 %\n",
      "------------------------------\n",
      "epoch/epochs: 30/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 40/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 50/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 60/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 70/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 80/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 90/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "epoch/epochs: 100/100\n",
      "accuracy:  100.0 %\n",
      "------------------------------\n",
      "saved to ./models/network1_[784, 500, 100].pth!\n",
      "model accuracy:  97.44 %\n",
      "------------------------------------------------------------\n",
      "ARCHITECTURE  0  | MODEL  2\n",
      "epoch/epochs: 10/100\n",
      "accuracy:  95.83333 %\n",
      "------------------------------\n",
      "epoch/epochs: 20/100\n",
      "accuracy:  97.91667 %\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train a bunch of networks\n",
    "architectures = [[784,500,100],\n",
    "                [784,900,500,100],\n",
    "                [784,256,64,32],\n",
    "                [784,256,128,64,32]]\n",
    "\n",
    "for i,layers in enumerate(architectures):\n",
    "    for j in range(4):\n",
    "        print('------------------------------------------------------------')\n",
    "        print('ARCHITECTURE ',i,' | MODEL ', j)\n",
    "        net = Net(layers,net_num=j,dev=device)\n",
    "        net.train(data_loader_train1, n_epochs=100)\n",
    "        net.accuracy(data_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a bunch of networks \n",
    "nets = []\n",
    "for i,layers in enumerate(architectures):\n",
    "    for j in range(4):\n",
    "        net = Net(layers,net_num=j,dev=device)\n",
    "        net.load()\n",
    "        nets.append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up for lime\n",
    "x_train = dataset.data.float().to(device)\n",
    "y_train = dataset.targets.float().to(device)\n",
    "x_test = dataset_test.data.float().to(device)\n",
    "y_test = dataset_test.targets.float().to(device)\n",
    "\n",
    "f_names = np.arange(0,28*28) \n",
    "c_names = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "class model_wrap():\n",
    "    def __init__(self,model,dev='cpu'):\n",
    "        self.model = model\n",
    "        self.dev = dev\n",
    "    \n",
    "    def predict_proba(self,x):\n",
    "        try:\n",
    "            x = torch.from_numpy(x).float().to(self.dev)\n",
    "        except:\n",
    "            x = x.float().to(self.dev)\n",
    "        try:\n",
    "            output = self.model(x).cpu().detach().numpy()\n",
    "        except:\n",
    "            output = self.model(x)\n",
    "        return output\n",
    "        \n",
    "def make_exp_vec(exp):\n",
    "    \"\"\"\n",
    "    Takes a LIME explanation which is a dictionary (i, w(i)) where i is the feature id and w(i) is the weight \n",
    "    of the ith feature. With the explanation vector we generate, we can \n",
    "    Arg - \n",
    "        exp: LIME explanation\n",
    "    Returns - \n",
    "        v: explanation vector where v[i] = w(i)\n",
    "        y_pred: the prediction of the model\n",
    "    \"\"\"\n",
    "    k = list(exp.keys())[0]\n",
    "    l = exp[k]\n",
    "    v = np.zeros(len(l))\n",
    "    for (i,w) in l:\n",
    "        v[i] = w\n",
    "    y_pred = k\n",
    "    return v,y_pred\n",
    "\n",
    "def exp_point(point,X,model,f_names,c_names):\n",
    "    \"\"\"\n",
    "    The explanation vector for top label of a point in a certain data set.\n",
    "    Arg - \n",
    "        point: point to explain\n",
    "        X: data model was trained on\n",
    "        model: black box\n",
    "        f_names: names of features\n",
    "        c_names: names of classes\n",
    "    Returns - \n",
    "        v: explanation vector (see make_exp_vec())\n",
    "        y_pred: model prediction\n",
    "    \"\"\"\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(X, feature_names=f_names, class_names=c_names, discretize_continuous=False)\n",
    "    exp = explainer.explain_instance(point, model, num_features=len(point), top_labels=1)\n",
    "    return v, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_exp = x_test[0].reshape(28*28,).cpu().detach().numpy()\n",
    "tr_data = x_train.reshape(x_train.shape[0],28*28).cpu().detach().numpy()\n",
    "model = model_wrap(net1,dev=device).predict_proba\n",
    "v,y_pred = exp_point(point_exp,tr_data,model,f_names,c_names)\n",
    "\n",
    "exp_vecs = []\n",
    "for i,net in enumerate(nets):\n",
    "    model = model_wrap(net,dev=device).predict_proba\n",
    "    v,y_pred = exp_point(point_exp,tr_data,model,f_names,c_names)\n",
    "    exp_vecs.append(v)\n",
    "    plt.figure(i)\n",
    "    plt.imshow(v.reshape(28,28))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
