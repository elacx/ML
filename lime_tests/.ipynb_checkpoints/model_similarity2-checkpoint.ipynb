{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "# general\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from numpy import dot \n",
    "from sklearn.metrics import accuracy_score\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "# lime\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "# advertorch \n",
    "from advertorch.attacks import LinfPGDAttack\n",
    "# cpu / gpu\n",
    "if torch.cuda.is_available():  \n",
    "    device = 'cuda:0'\n",
    "else:  \n",
    "    device = 'cpu'\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain mnist data and process\n",
    "batch_size = 128\n",
    "\n",
    "dataset = MNIST('.', train=True, download=False,transform=transforms.ToTensor())\n",
    "dataset_test = MNIST('.', train=False, download=False,transform=transforms.ToTensor())\n",
    "\n",
    "train1, train2 = random_split(dataset,[30000,30000])#DataLoader(dataset, batch_size=batch_size)\n",
    "data_loader_train1 = DataLoader(train1, batch_size=batch_size)\n",
    "data_loader_train2 = DataLoader(train2, batch_size=batch_size)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch network \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, layers, num_classes=10, net_num=1, dev='cpu'):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.net_num = net_num\n",
    "        self.path = './models/network'+str(self.net_num)+'_'+str(self.layers)+'.pth'\n",
    "        self.dev = dev\n",
    "        # layers\n",
    "        self.fc_linears = nn.ModuleList()\n",
    "        for i in range(len(self.layers)-1):\n",
    "            self.fc_linears.append(nn.Sequential(nn.Linear(in_features=self.layers[i], out_features=self.layers[i+1]),nn.BatchNorm1d(self.layers[i+1]),nn.ReLU()))\n",
    "        self.f_final = nn.Linear(self.layers[-1],num_classes)\n",
    "        self.fc_linears.to(dev)\n",
    "        self.f_final.to(dev)\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        for l in self.fc_linears:\n",
    "            x = l(x)\n",
    "        x = softmax(self.f_final(x))\n",
    "        return x\n",
    "    \n",
    "    def train(self, train_data, loss_fn=nn.CrossEntropyLoss(), n_epochs=50, save=True):\n",
    "        for epoch in range(n_epochs):\n",
    "            for data,target in train_data:\n",
    "                data, target = data.reshape(data.shape[0],28*28).to(self.dev),target.to(self.dev)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.forward(data)\n",
    "                loss = loss_fn(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            if (epoch+1)%10 == 0:\n",
    "                print('epoch/epochs: '+str(epoch+1)+'/'+str(n_epochs))\n",
    "                print('accuracy: ', round((torch.argmax(output,dim=1) == target).sum().item()/len(target)*100.,5), '%')\n",
    "                print('------------------------------')\n",
    "        if save:\n",
    "            torch.save(self.state_dict(), self.path)\n",
    "            print('saved to '+self.path+'!')\n",
    "            \n",
    "    def accuracy(self, test_data):\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        for x,y in test_data:\n",
    "            x,y = x.reshape(x.shape[0],28*28).to(self.dev),y.to(self.dev)\n",
    "            output = self.forward(x)\n",
    "            correct += (torch.argmax(output,dim=1) == y).sum().item()\n",
    "            total += len(y)\n",
    "        print('model accuracy: ',round((correct/total)*100,5),'%')\n",
    "        \n",
    "    def load(self):\n",
    "        self.load_state_dict(torch.load(self.path))\n",
    "        print('model loaded from ', self.path, '!')\n",
    "        \n",
    "class CNet(nn.Module):\n",
    "    def __init__(self, c_layers, num_classes=10, net_num=1, dev='cpu'):\n",
    "        super(CNet, self).__init__()\n",
    "        self.c_layers = c_layers\n",
    "        self.net_num = net_num\n",
    "        self.path = './models/network_CNN_'+str(self.net_num)+'_'+str(self.c_layers)+'.pth'\n",
    "        self.dev = dev\n",
    "        self.relu = nn.ReLU()\n",
    "        # conv layers\n",
    "        self.convs = nn.ModuleList()   \n",
    "        h = torch.rand(1,1,28,28)\n",
    "        for c_layer in c_layers:\n",
    "            layer = nn.Sequential(nn.Conv2d(c_layer[0],c_layer[1],c_layer[2],c_layer[3]),nn.BatchNorm2d(c_layer[1]),self.relu)\n",
    "            self.convs.append(layer)\n",
    "            h = layer(h)\n",
    "        h = torch.flatten(h,start_dim=1)\n",
    "        self.linshape = h.shape[-1]\n",
    "        self.linear1 = nn.Linear(self.linshape,int(self.linshape/2))\n",
    "        self.batch_norm = nn.BatchNorm1d(int(self.linshape/2))\n",
    "        self.linear2 = nn.Linear(int(self.linshape/2),num_classes)\n",
    "        self.convs.to(dev)\n",
    "        self.linear1.to(dev)\n",
    "        self.batch_norm.to(dev)\n",
    "        self.linear2.to(dev)\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        for cl in self.convs:\n",
    "            x = cl(x)\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "        x = self.relu(self.batch_norm(self.linear1(x)))\n",
    "        x = softmax(self.linear2(x))\n",
    "        return x\n",
    "    \n",
    "    def train(self, train_data, loss_fn=nn.CrossEntropyLoss(), n_epochs=50, save=True):\n",
    "        for epoch in range(n_epochs):\n",
    "            for data,target in train_data:\n",
    "                data, target = data.to(self.dev),target.to(self.dev)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.forward(data)\n",
    "                loss = loss_fn(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            if (epoch+1)%10 == 0:\n",
    "                print('epoch/epochs: '+str(epoch+1)+'/'+str(n_epochs))\n",
    "                print('accuracy: ', round((torch.argmax(output,dim=1) == target).sum().item()/len(target)*100.,5), '%')\n",
    "                print('------------------------------')\n",
    "        if save:\n",
    "            torch.save(self.state_dict(), self.path)\n",
    "            print('saved to '+self.path+'!')\n",
    "            \n",
    "    def accuracy(self, test_data):\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        for x,y in test_data:\n",
    "            x,y = x.to(self.dev),y.to(self.dev)\n",
    "            output = self.forward(x)\n",
    "            correct += (torch.argmax(output,dim=1) == y).sum().item()\n",
    "            total += len(y)\n",
    "        print('model accuracy: ',round((correct/total)*100,5),'%')\n",
    "        \n",
    "    def load(self):\n",
    "        self.load_state_dict(torch.load(self.path))\n",
    "        print('model loaded from ', self.path, '!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "ARCHITECTURE  3  | MODEL  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5f3c91976216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ARCHITECTURE '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' | MODEL '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitectures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d6142d281b24>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, loss_fn, n_epochs, save)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exml/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exml/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exml/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exml/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exml/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exml/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exml/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exml/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train a bunch of networks\n",
    "# architectures = [[784,500,100],\n",
    "#                 [784,900,500,100],\n",
    "#                 [784,256,64,32],\n",
    "#                 [784,256,128,64,32]]\n",
    "\n",
    "# for i,layers in enumerate(architectures):\n",
    "#     for j in range(4):\n",
    "#         print('------------------------------------------------------------')\n",
    "#         print('ARCHITECTURE ',i,' | MODEL ', j)\n",
    "#         net = Net(layers,net_num=j,dev=device)\n",
    "#         net.train(data_loader_train1, n_epochs=50)\n",
    "#         net.accuracy(data_loader_test)\n",
    "\n",
    "# train a bunch of CNNs \n",
    "architectures = [[(1,2,2,1),(2,3,2,1),(3,4,1,1)],\n",
    "                [(1,3,2,1),(3,4,2,1)],\n",
    "                [(1,2,3,3),(2,3,3,3)],\n",
    "                [(1,2,3,3),(2,3,3,3),(3,4,1,1)]]\n",
    "\n",
    "# for i,layers in enumerate(architectures):\n",
    "#     for j in range(4):\n",
    "#         print('------------------------------------------------------------')\n",
    "#         print('ARCHITECTURE ',i,' | MODEL ', j)\n",
    "#         net = CNet(layers,net_num=j,dev=device)\n",
    "#         net.train(data_loader_train1, n_epochs=100)\n",
    "#         net.accuracy(data_loader_test)\n",
    "\n",
    "# for j in range(4):\n",
    "#     print('------------------------------------------------------------')\n",
    "#     print('ARCHITECTURE ',3,' | MODEL ', j)\n",
    "#     net = CNet(architectures[-1],net_num=j,dev=device)\n",
    "#     net.train(data_loader_train1, n_epochs=100)\n",
    "#     net.accuracy(data_loader_test)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from  ./models/network_CNN_0_[(1, 2, 2, 1), (2, 3, 2, 1), (3, 4, 1, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_1_[(1, 2, 2, 1), (2, 3, 2, 1), (3, 4, 1, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_2_[(1, 2, 2, 1), (2, 3, 2, 1), (3, 4, 1, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_3_[(1, 2, 2, 1), (2, 3, 2, 1), (3, 4, 1, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_0_[(1, 3, 2, 1), (3, 4, 2, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_1_[(1, 3, 2, 1), (3, 4, 2, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_2_[(1, 3, 2, 1), (3, 4, 2, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_3_[(1, 3, 2, 1), (3, 4, 2, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_0_[(1, 2, 3, 3), (2, 3, 3, 3)].pth !\n",
      "model loaded from  ./models/network_CNN_1_[(1, 2, 3, 3), (2, 3, 3, 3)].pth !\n",
      "model loaded from  ./models/network_CNN_2_[(1, 2, 3, 3), (2, 3, 3, 3)].pth !\n",
      "model loaded from  ./models/network_CNN_3_[(1, 2, 3, 3), (2, 3, 3, 3)].pth !\n",
      "model loaded from  ./models/network_CNN_0_[(1, 2, 3, 3), (2, 3, 3, 3), (3, 4, 1, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_1_[(1, 2, 3, 3), (2, 3, 3, 3), (3, 4, 1, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_2_[(1, 2, 3, 3), (2, 3, 3, 3), (3, 4, 1, 1)].pth !\n",
      "model loaded from  ./models/network_CNN_3_[(1, 2, 3, 3), (2, 3, 3, 3), (3, 4, 1, 1)].pth !\n"
     ]
    }
   ],
   "source": [
    "# load a bunch of networks \n",
    "# architectures = [[784,500,100],\n",
    "#                 [784,900,500,100],\n",
    "#                 [784,256,64,32],\n",
    "#                 [784,256,128,64,32]]\n",
    "# nets = []\n",
    "# for i,layers in enumerate(architectures):\n",
    "#     for j in range(4):\n",
    "#         net = Net(layers,net_num=j,dev=device)\n",
    "#         net.load()\n",
    "#         nets.append(net)\n",
    "\n",
    "# load a bunch of CNNs \n",
    "architectures = [[(1,2,2,1),(2,3,2,1),(3,4,1,1)],\n",
    "                [(1,3,2,1),(3,4,2,1)],\n",
    "                [(1,2,3,3),(2,3,3,3)],\n",
    "                [(1,2,3,3),(2,3,3,3),(3,4,1,1)]]\n",
    "nets = []\n",
    "for i,layers in enumerate(architectures):\n",
    "    for j in range(4):\n",
    "        net = CNet(layers,net_num=j,dev=device)\n",
    "        net.load()\n",
    "        nets.append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 2, 27, 27]              10\n",
      "       BatchNorm2d-2            [-1, 2, 27, 27]               4\n",
      "              ReLU-3            [-1, 2, 27, 27]               0\n",
      "              ReLU-4            [-1, 2, 27, 27]               0\n",
      "              ReLU-5            [-1, 2, 27, 27]               0\n",
      "              ReLU-6            [-1, 2, 27, 27]               0\n",
      "            Conv2d-7            [-1, 3, 26, 26]              27\n",
      "       BatchNorm2d-8            [-1, 3, 26, 26]               6\n",
      "              ReLU-9            [-1, 3, 26, 26]               0\n",
      "             ReLU-10            [-1, 3, 26, 26]               0\n",
      "             ReLU-11            [-1, 3, 26, 26]               0\n",
      "             ReLU-12            [-1, 3, 26, 26]               0\n",
      "           Conv2d-13            [-1, 4, 26, 26]              16\n",
      "      BatchNorm2d-14            [-1, 4, 26, 26]               8\n",
      "             ReLU-15            [-1, 4, 26, 26]               0\n",
      "             ReLU-16            [-1, 4, 26, 26]               0\n",
      "             ReLU-17            [-1, 4, 26, 26]               0\n",
      "             ReLU-18            [-1, 4, 26, 26]               0\n",
      "           Linear-19                 [-1, 1352]       3,657,160\n",
      "      BatchNorm1d-20                 [-1, 1352]           2,704\n",
      "             ReLU-21                 [-1, 1352]               0\n",
      "             ReLU-22                 [-1, 1352]               0\n",
      "             ReLU-23                 [-1, 1352]               0\n",
      "             ReLU-24                 [-1, 1352]               0\n",
      "           Linear-25                   [-1, 10]          13,530\n",
      "================================================================\n",
      "Total params: 3,673,465\n",
      "Trainable params: 3,673,465\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 14.01\n",
      "Estimated Total Size (MB): 14.36\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 2, 27, 27]              10\n",
      "       BatchNorm2d-2            [-1, 2, 27, 27]               4\n",
      "              ReLU-3            [-1, 2, 27, 27]               0\n",
      "              ReLU-4            [-1, 2, 27, 27]               0\n",
      "              ReLU-5            [-1, 2, 27, 27]               0\n",
      "              ReLU-6            [-1, 2, 27, 27]               0\n",
      "            Conv2d-7            [-1, 3, 26, 26]              27\n",
      "       BatchNorm2d-8            [-1, 3, 26, 26]               6\n",
      "              ReLU-9            [-1, 3, 26, 26]               0\n",
      "             ReLU-10            [-1, 3, 26, 26]               0\n",
      "             ReLU-11            [-1, 3, 26, 26]               0\n",
      "             ReLU-12            [-1, 3, 26, 26]               0\n",
      "           Conv2d-13            [-1, 4, 26, 26]              16\n",
      "      BatchNorm2d-14            [-1, 4, 26, 26]               8\n",
      "             ReLU-15            [-1, 4, 26, 26]               0\n",
      "             ReLU-16            [-1, 4, 26, 26]               0\n",
      "             ReLU-17            [-1, 4, 26, 26]               0\n",
      "             ReLU-18            [-1, 4, 26, 26]               0\n",
      "           Linear-19                 [-1, 1352]       3,657,160\n",
      "      BatchNorm1d-20                 [-1, 1352]           2,704\n",
      "             ReLU-21                 [-1, 1352]               0\n",
      "             ReLU-22                 [-1, 1352]               0\n",
      "             ReLU-23                 [-1, 1352]               0\n",
      "             ReLU-24                 [-1, 1352]               0\n",
      "           Linear-25                   [-1, 10]          13,530\n",
      "================================================================\n",
      "Total params: 3,673,465\n",
      "Trainable params: 3,673,465\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 14.01\n",
      "Estimated Total Size (MB): 14.36\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 2, 27, 27]              10\n",
      "       BatchNorm2d-2            [-1, 2, 27, 27]               4\n",
      "              ReLU-3            [-1, 2, 27, 27]               0\n",
      "              ReLU-4            [-1, 2, 27, 27]               0\n",
      "              ReLU-5            [-1, 2, 27, 27]               0\n",
      "              ReLU-6            [-1, 2, 27, 27]               0\n",
      "            Conv2d-7            [-1, 3, 26, 26]              27\n",
      "       BatchNorm2d-8            [-1, 3, 26, 26]               6\n",
      "              ReLU-9            [-1, 3, 26, 26]               0\n",
      "             ReLU-10            [-1, 3, 26, 26]               0\n",
      "             ReLU-11            [-1, 3, 26, 26]               0\n",
      "             ReLU-12            [-1, 3, 26, 26]               0\n",
      "           Conv2d-13            [-1, 4, 26, 26]              16\n",
      "      BatchNorm2d-14            [-1, 4, 26, 26]               8\n",
      "             ReLU-15            [-1, 4, 26, 26]               0\n",
      "             ReLU-16            [-1, 4, 26, 26]               0\n",
      "             ReLU-17            [-1, 4, 26, 26]               0\n",
      "             ReLU-18            [-1, 4, 26, 26]               0\n",
      "           Linear-19                 [-1, 1352]       3,657,160\n",
      "      BatchNorm1d-20                 [-1, 1352]           2,704\n",
      "             ReLU-21                 [-1, 1352]               0\n",
      "             ReLU-22                 [-1, 1352]               0\n",
      "             ReLU-23                 [-1, 1352]               0\n",
      "             ReLU-24                 [-1, 1352]               0\n",
      "           Linear-25                   [-1, 10]          13,530\n",
      "================================================================\n",
      "Total params: 3,673,465\n",
      "Trainable params: 3,673,465\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 14.01\n",
      "Estimated Total Size (MB): 14.36\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 2, 27, 27]              10\n",
      "       BatchNorm2d-2            [-1, 2, 27, 27]               4\n",
      "              ReLU-3            [-1, 2, 27, 27]               0\n",
      "              ReLU-4            [-1, 2, 27, 27]               0\n",
      "              ReLU-5            [-1, 2, 27, 27]               0\n",
      "              ReLU-6            [-1, 2, 27, 27]               0\n",
      "            Conv2d-7            [-1, 3, 26, 26]              27\n",
      "       BatchNorm2d-8            [-1, 3, 26, 26]               6\n",
      "              ReLU-9            [-1, 3, 26, 26]               0\n",
      "             ReLU-10            [-1, 3, 26, 26]               0\n",
      "             ReLU-11            [-1, 3, 26, 26]               0\n",
      "             ReLU-12            [-1, 3, 26, 26]               0\n",
      "           Conv2d-13            [-1, 4, 26, 26]              16\n",
      "      BatchNorm2d-14            [-1, 4, 26, 26]               8\n",
      "             ReLU-15            [-1, 4, 26, 26]               0\n",
      "             ReLU-16            [-1, 4, 26, 26]               0\n",
      "             ReLU-17            [-1, 4, 26, 26]               0\n",
      "             ReLU-18            [-1, 4, 26, 26]               0\n",
      "           Linear-19                 [-1, 1352]       3,657,160\n",
      "      BatchNorm1d-20                 [-1, 1352]           2,704\n",
      "             ReLU-21                 [-1, 1352]               0\n",
      "             ReLU-22                 [-1, 1352]               0\n",
      "             ReLU-23                 [-1, 1352]               0\n",
      "             ReLU-24                 [-1, 1352]               0\n",
      "           Linear-25                   [-1, 10]          13,530\n",
      "================================================================\n",
      "Total params: 3,673,465\n",
      "Trainable params: 3,673,465\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 14.01\n",
      "Estimated Total Size (MB): 14.36\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 27, 27]              15\n",
      "       BatchNorm2d-2            [-1, 3, 27, 27]               6\n",
      "              ReLU-3            [-1, 3, 27, 27]               0\n",
      "              ReLU-4            [-1, 3, 27, 27]               0\n",
      "              ReLU-5            [-1, 3, 27, 27]               0\n",
      "            Conv2d-6            [-1, 4, 26, 26]              52\n",
      "       BatchNorm2d-7            [-1, 4, 26, 26]               8\n",
      "              ReLU-8            [-1, 4, 26, 26]               0\n",
      "              ReLU-9            [-1, 4, 26, 26]               0\n",
      "             ReLU-10            [-1, 4, 26, 26]               0\n",
      "           Linear-11                 [-1, 1352]       3,657,160\n",
      "      BatchNorm1d-12                 [-1, 1352]           2,704\n",
      "             ReLU-13                 [-1, 1352]               0\n",
      "             ReLU-14                 [-1, 1352]               0\n",
      "             ReLU-15                 [-1, 1352]               0\n",
      "           Linear-16                   [-1, 10]          13,530\n",
      "================================================================\n",
      "Total params: 3,673,475\n",
      "Trainable params: 3,673,475\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.24\n",
      "Params size (MB): 14.01\n",
      "Estimated Total Size (MB): 14.25\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 27, 27]              15\n",
      "       BatchNorm2d-2            [-1, 3, 27, 27]               6\n",
      "              ReLU-3            [-1, 3, 27, 27]               0\n",
      "              ReLU-4            [-1, 3, 27, 27]               0\n",
      "              ReLU-5            [-1, 3, 27, 27]               0\n",
      "            Conv2d-6            [-1, 4, 26, 26]              52\n",
      "       BatchNorm2d-7            [-1, 4, 26, 26]               8\n",
      "              ReLU-8            [-1, 4, 26, 26]               0\n",
      "              ReLU-9            [-1, 4, 26, 26]               0\n",
      "             ReLU-10            [-1, 4, 26, 26]               0\n",
      "           Linear-11                 [-1, 1352]       3,657,160\n",
      "      BatchNorm1d-12                 [-1, 1352]           2,704\n",
      "             ReLU-13                 [-1, 1352]               0\n",
      "             ReLU-14                 [-1, 1352]               0\n",
      "             ReLU-15                 [-1, 1352]               0\n",
      "           Linear-16                   [-1, 10]          13,530\n",
      "================================================================\n",
      "Total params: 3,673,475\n",
      "Trainable params: 3,673,475\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.24\n",
      "Params size (MB): 14.01\n",
      "Estimated Total Size (MB): 14.25\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 27, 27]              15\n",
      "       BatchNorm2d-2            [-1, 3, 27, 27]               6\n",
      "              ReLU-3            [-1, 3, 27, 27]               0\n",
      "              ReLU-4            [-1, 3, 27, 27]               0\n",
      "              ReLU-5            [-1, 3, 27, 27]               0\n",
      "            Conv2d-6            [-1, 4, 26, 26]              52\n",
      "       BatchNorm2d-7            [-1, 4, 26, 26]               8\n",
      "              ReLU-8            [-1, 4, 26, 26]               0\n",
      "              ReLU-9            [-1, 4, 26, 26]               0\n",
      "             ReLU-10            [-1, 4, 26, 26]               0\n",
      "           Linear-11                 [-1, 1352]       3,657,160\n",
      "      BatchNorm1d-12                 [-1, 1352]           2,704\n",
      "             ReLU-13                 [-1, 1352]               0\n",
      "             ReLU-14                 [-1, 1352]               0\n",
      "             ReLU-15                 [-1, 1352]               0\n",
      "           Linear-16                   [-1, 10]          13,530\n",
      "================================================================\n",
      "Total params: 3,673,475\n",
      "Trainable params: 3,673,475\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.24\n",
      "Params size (MB): 14.01\n",
      "Estimated Total Size (MB): 14.25\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 27, 27]              15\n",
      "       BatchNorm2d-2            [-1, 3, 27, 27]               6\n",
      "              ReLU-3            [-1, 3, 27, 27]               0\n",
      "              ReLU-4            [-1, 3, 27, 27]               0\n",
      "              ReLU-5            [-1, 3, 27, 27]               0\n",
      "            Conv2d-6            [-1, 4, 26, 26]              52\n",
      "       BatchNorm2d-7            [-1, 4, 26, 26]               8\n",
      "              ReLU-8            [-1, 4, 26, 26]               0\n",
      "              ReLU-9            [-1, 4, 26, 26]               0\n",
      "             ReLU-10            [-1, 4, 26, 26]               0\n",
      "           Linear-11                 [-1, 1352]       3,657,160\n",
      "      BatchNorm1d-12                 [-1, 1352]           2,704\n",
      "             ReLU-13                 [-1, 1352]               0\n",
      "             ReLU-14                 [-1, 1352]               0\n",
      "             ReLU-15                 [-1, 1352]               0\n",
      "           Linear-16                   [-1, 10]          13,530\n",
      "================================================================\n",
      "Total params: 3,673,475\n",
      "Trainable params: 3,673,475\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.24\n",
      "Params size (MB): 14.01\n",
      "Estimated Total Size (MB): 14.25\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 2, 9, 9]              20\n",
      "       BatchNorm2d-2              [-1, 2, 9, 9]               4\n",
      "              ReLU-3              [-1, 2, 9, 9]               0\n",
      "              ReLU-4              [-1, 2, 9, 9]               0\n",
      "              ReLU-5              [-1, 2, 9, 9]               0\n",
      "            Conv2d-6              [-1, 3, 3, 3]              57\n",
      "       BatchNorm2d-7              [-1, 3, 3, 3]               6\n",
      "              ReLU-8              [-1, 3, 3, 3]               0\n",
      "              ReLU-9              [-1, 3, 3, 3]               0\n",
      "             ReLU-10              [-1, 3, 3, 3]               0\n",
      "           Linear-11                   [-1, 13]             364\n",
      "      BatchNorm1d-12                   [-1, 13]              26\n",
      "             ReLU-13                   [-1, 13]               0\n",
      "             ReLU-14                   [-1, 13]               0\n",
      "             ReLU-15                   [-1, 13]               0\n",
      "           Linear-16                   [-1, 10]             140\n",
      "================================================================\n",
      "Total params: 617\n",
      "Trainable params: 617\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 2, 9, 9]              20\n",
      "       BatchNorm2d-2              [-1, 2, 9, 9]               4\n",
      "              ReLU-3              [-1, 2, 9, 9]               0\n",
      "              ReLU-4              [-1, 2, 9, 9]               0\n",
      "              ReLU-5              [-1, 2, 9, 9]               0\n",
      "            Conv2d-6              [-1, 3, 3, 3]              57\n",
      "       BatchNorm2d-7              [-1, 3, 3, 3]               6\n",
      "              ReLU-8              [-1, 3, 3, 3]               0\n",
      "              ReLU-9              [-1, 3, 3, 3]               0\n",
      "             ReLU-10              [-1, 3, 3, 3]               0\n",
      "           Linear-11                   [-1, 13]             364\n",
      "      BatchNorm1d-12                   [-1, 13]              26\n",
      "             ReLU-13                   [-1, 13]               0\n",
      "             ReLU-14                   [-1, 13]               0\n",
      "             ReLU-15                   [-1, 13]               0\n",
      "           Linear-16                   [-1, 10]             140\n",
      "================================================================\n",
      "Total params: 617\n",
      "Trainable params: 617\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 2, 9, 9]              20\n",
      "       BatchNorm2d-2              [-1, 2, 9, 9]               4\n",
      "              ReLU-3              [-1, 2, 9, 9]               0\n",
      "              ReLU-4              [-1, 2, 9, 9]               0\n",
      "              ReLU-5              [-1, 2, 9, 9]               0\n",
      "            Conv2d-6              [-1, 3, 3, 3]              57\n",
      "       BatchNorm2d-7              [-1, 3, 3, 3]               6\n",
      "              ReLU-8              [-1, 3, 3, 3]               0\n",
      "              ReLU-9              [-1, 3, 3, 3]               0\n",
      "             ReLU-10              [-1, 3, 3, 3]               0\n",
      "           Linear-11                   [-1, 13]             364\n",
      "      BatchNorm1d-12                   [-1, 13]              26\n",
      "             ReLU-13                   [-1, 13]               0\n",
      "             ReLU-14                   [-1, 13]               0\n",
      "             ReLU-15                   [-1, 13]               0\n",
      "           Linear-16                   [-1, 10]             140\n",
      "================================================================\n",
      "Total params: 617\n",
      "Trainable params: 617\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 2, 9, 9]              20\n",
      "       BatchNorm2d-2              [-1, 2, 9, 9]               4\n",
      "              ReLU-3              [-1, 2, 9, 9]               0\n",
      "              ReLU-4              [-1, 2, 9, 9]               0\n",
      "              ReLU-5              [-1, 2, 9, 9]               0\n",
      "            Conv2d-6              [-1, 3, 3, 3]              57\n",
      "       BatchNorm2d-7              [-1, 3, 3, 3]               6\n",
      "              ReLU-8              [-1, 3, 3, 3]               0\n",
      "              ReLU-9              [-1, 3, 3, 3]               0\n",
      "             ReLU-10              [-1, 3, 3, 3]               0\n",
      "           Linear-11                   [-1, 13]             364\n",
      "      BatchNorm1d-12                   [-1, 13]              26\n",
      "             ReLU-13                   [-1, 13]               0\n",
      "             ReLU-14                   [-1, 13]               0\n",
      "             ReLU-15                   [-1, 13]               0\n",
      "           Linear-16                   [-1, 10]             140\n",
      "================================================================\n",
      "Total params: 617\n",
      "Trainable params: 617\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 2, 9, 9]              20\n",
      "       BatchNorm2d-2              [-1, 2, 9, 9]               4\n",
      "              ReLU-3              [-1, 2, 9, 9]               0\n",
      "              ReLU-4              [-1, 2, 9, 9]               0\n",
      "              ReLU-5              [-1, 2, 9, 9]               0\n",
      "              ReLU-6              [-1, 2, 9, 9]               0\n",
      "            Conv2d-7              [-1, 3, 3, 3]              57\n",
      "       BatchNorm2d-8              [-1, 3, 3, 3]               6\n",
      "              ReLU-9              [-1, 3, 3, 3]               0\n",
      "             ReLU-10              [-1, 3, 3, 3]               0\n",
      "             ReLU-11              [-1, 3, 3, 3]               0\n",
      "             ReLU-12              [-1, 3, 3, 3]               0\n",
      "           Conv2d-13              [-1, 4, 3, 3]              16\n",
      "      BatchNorm2d-14              [-1, 4, 3, 3]               8\n",
      "             ReLU-15              [-1, 4, 3, 3]               0\n",
      "             ReLU-16              [-1, 4, 3, 3]               0\n",
      "             ReLU-17              [-1, 4, 3, 3]               0\n",
      "             ReLU-18              [-1, 4, 3, 3]               0\n",
      "           Linear-19                   [-1, 18]             666\n",
      "      BatchNorm1d-20                   [-1, 18]              36\n",
      "             ReLU-21                   [-1, 18]               0\n",
      "             ReLU-22                   [-1, 18]               0\n",
      "             ReLU-23                   [-1, 18]               0\n",
      "             ReLU-24                   [-1, 18]               0\n",
      "           Linear-25                   [-1, 10]             190\n",
      "================================================================\n",
      "Total params: 1,003\n",
      "Trainable params: 1,003\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 2, 9, 9]              20\n",
      "       BatchNorm2d-2              [-1, 2, 9, 9]               4\n",
      "              ReLU-3              [-1, 2, 9, 9]               0\n",
      "              ReLU-4              [-1, 2, 9, 9]               0\n",
      "              ReLU-5              [-1, 2, 9, 9]               0\n",
      "              ReLU-6              [-1, 2, 9, 9]               0\n",
      "            Conv2d-7              [-1, 3, 3, 3]              57\n",
      "       BatchNorm2d-8              [-1, 3, 3, 3]               6\n",
      "              ReLU-9              [-1, 3, 3, 3]               0\n",
      "             ReLU-10              [-1, 3, 3, 3]               0\n",
      "             ReLU-11              [-1, 3, 3, 3]               0\n",
      "             ReLU-12              [-1, 3, 3, 3]               0\n",
      "           Conv2d-13              [-1, 4, 3, 3]              16\n",
      "      BatchNorm2d-14              [-1, 4, 3, 3]               8\n",
      "             ReLU-15              [-1, 4, 3, 3]               0\n",
      "             ReLU-16              [-1, 4, 3, 3]               0\n",
      "             ReLU-17              [-1, 4, 3, 3]               0\n",
      "             ReLU-18              [-1, 4, 3, 3]               0\n",
      "           Linear-19                   [-1, 18]             666\n",
      "      BatchNorm1d-20                   [-1, 18]              36\n",
      "             ReLU-21                   [-1, 18]               0\n",
      "             ReLU-22                   [-1, 18]               0\n",
      "             ReLU-23                   [-1, 18]               0\n",
      "             ReLU-24                   [-1, 18]               0\n",
      "           Linear-25                   [-1, 10]             190\n",
      "================================================================\n",
      "Total params: 1,003\n",
      "Trainable params: 1,003\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 2, 9, 9]              20\n",
      "       BatchNorm2d-2              [-1, 2, 9, 9]               4\n",
      "              ReLU-3              [-1, 2, 9, 9]               0\n",
      "              ReLU-4              [-1, 2, 9, 9]               0\n",
      "              ReLU-5              [-1, 2, 9, 9]               0\n",
      "              ReLU-6              [-1, 2, 9, 9]               0\n",
      "            Conv2d-7              [-1, 3, 3, 3]              57\n",
      "       BatchNorm2d-8              [-1, 3, 3, 3]               6\n",
      "              ReLU-9              [-1, 3, 3, 3]               0\n",
      "             ReLU-10              [-1, 3, 3, 3]               0\n",
      "             ReLU-11              [-1, 3, 3, 3]               0\n",
      "             ReLU-12              [-1, 3, 3, 3]               0\n",
      "           Conv2d-13              [-1, 4, 3, 3]              16\n",
      "      BatchNorm2d-14              [-1, 4, 3, 3]               8\n",
      "             ReLU-15              [-1, 4, 3, 3]               0\n",
      "             ReLU-16              [-1, 4, 3, 3]               0\n",
      "             ReLU-17              [-1, 4, 3, 3]               0\n",
      "             ReLU-18              [-1, 4, 3, 3]               0\n",
      "           Linear-19                   [-1, 18]             666\n",
      "      BatchNorm1d-20                   [-1, 18]              36\n",
      "             ReLU-21                   [-1, 18]               0\n",
      "             ReLU-22                   [-1, 18]               0\n",
      "             ReLU-23                   [-1, 18]               0\n",
      "             ReLU-24                   [-1, 18]               0\n",
      "           Linear-25                   [-1, 10]             190\n",
      "================================================================\n",
      "Total params: 1,003\n",
      "Trainable params: 1,003\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 2, 9, 9]              20\n",
      "       BatchNorm2d-2              [-1, 2, 9, 9]               4\n",
      "              ReLU-3              [-1, 2, 9, 9]               0\n",
      "              ReLU-4              [-1, 2, 9, 9]               0\n",
      "              ReLU-5              [-1, 2, 9, 9]               0\n",
      "              ReLU-6              [-1, 2, 9, 9]               0\n",
      "            Conv2d-7              [-1, 3, 3, 3]              57\n",
      "       BatchNorm2d-8              [-1, 3, 3, 3]               6\n",
      "              ReLU-9              [-1, 3, 3, 3]               0\n",
      "             ReLU-10              [-1, 3, 3, 3]               0\n",
      "             ReLU-11              [-1, 3, 3, 3]               0\n",
      "             ReLU-12              [-1, 3, 3, 3]               0\n",
      "           Conv2d-13              [-1, 4, 3, 3]              16\n",
      "      BatchNorm2d-14              [-1, 4, 3, 3]               8\n",
      "             ReLU-15              [-1, 4, 3, 3]               0\n",
      "             ReLU-16              [-1, 4, 3, 3]               0\n",
      "             ReLU-17              [-1, 4, 3, 3]               0\n",
      "             ReLU-18              [-1, 4, 3, 3]               0\n",
      "           Linear-19                   [-1, 18]             666\n",
      "      BatchNorm1d-20                   [-1, 18]              36\n",
      "             ReLU-21                   [-1, 18]               0\n",
      "             ReLU-22                   [-1, 18]               0\n",
      "             ReLU-23                   [-1, 18]               0\n",
      "             ReLU-24                   [-1, 18]               0\n",
      "           Linear-25                   [-1, 10]             190\n",
      "================================================================\n",
      "Total params: 1,003\n",
      "Trainable params: 1,003\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for net in nets:\n",
    "    summary(net,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up for lime\n",
    "x_train = dataset.data.float().to(device)\n",
    "y_train = dataset.targets.float().to(device)\n",
    "x_test = dataset_test.data.float().to(device)\n",
    "y_test = dataset_test.targets.float().to(device)\n",
    "\n",
    "f_names = np.arange(0,28*28) \n",
    "c_names = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "class model_wrap():\n",
    "    def __init__(self,model,dev='cpu'):\n",
    "        self.model = model\n",
    "        self.dev = dev\n",
    "    \n",
    "    def predict_proba(self,x):\n",
    "        try:\n",
    "            x = torch.from_numpy(x).float().to(self.dev)\n",
    "        except:\n",
    "            x = x.float().to(self.dev)\n",
    "        try:\n",
    "            output = self.model(x).cpu().detach().numpy()\n",
    "        except:\n",
    "            output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "class CNN_model_wrap():\n",
    "    def __init__(self,model,dev='cpu'):\n",
    "        self.model = model\n",
    "        self.dev = dev\n",
    "    \n",
    "    def predict_proba(self,x):\n",
    "        try:\n",
    "            x = torch.from_numpy(x).float().to(self.dev)\n",
    "            x = x.reshape(x.shape[0],1,28,28)\n",
    "        except:\n",
    "            x = x.float().to(self.dev)\n",
    "            x = x.reshape(x.shape[0],1,28,28)\n",
    "        try:\n",
    "            output = self.model(x).cpu().detach().numpy()\n",
    "        except:\n",
    "            output = self.model(x)\n",
    "        return output\n",
    "        \n",
    "def make_exp_vec(exp):\n",
    "    \"\"\"\n",
    "    Takes a LIME explanation which is a dictionary (i, w(i)) where i is the feature id and w(i) is the weight \n",
    "    of the ith feature. With the explanation vector we generate, we can \n",
    "    Arg - \n",
    "        exp: LIME explanation\n",
    "    Returns - \n",
    "        v: explanation vector where v[i] = w(i)\n",
    "        y_pred: the prediction of the model\n",
    "    \"\"\"\n",
    "    k = list(exp.keys())[0]\n",
    "    l = exp[k]\n",
    "    v = np.zeros(len(l))\n",
    "    for (i,w) in l:\n",
    "        v[i] = w\n",
    "    y_pred = k\n",
    "    return v,y_pred\n",
    "\n",
    "def exp_point(point,X,model,f_names,c_names):\n",
    "    \"\"\"\n",
    "    The explanation vector for top label of a point in a certain data set.\n",
    "    Arg - \n",
    "        point: point to explain\n",
    "        X: data model was trained on\n",
    "        model: black box\n",
    "        f_names: names of features\n",
    "        c_names: names of classes\n",
    "    Returns - \n",
    "        v: explanation vector (see make_exp_vec())\n",
    "        y_pred: model prediction\n",
    "    \"\"\"\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(X, feature_names=f_names, class_names=c_names, discretize_continuous=False)\n",
    "    exp = explainer.explain_instance(point, model, num_features=len(point), top_labels=1)\n",
    "    v,y_pred = make_exp_vec(exp.local_exp)\n",
    "    return v, y_pred\n",
    "\n",
    "def cos_sim(v,w):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors.\n",
    "    Arg - \n",
    "        v: numpy array like a vector\n",
    "        w: numpy array like a vector\n",
    "    Returns - \n",
    "        sim: cosine similarity of the two vectors\n",
    "    \"\"\"\n",
    "    return np.dot(v,w)/(norm(v)*norm(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_exp = x_test[0].reshape(28*28,).cpu().detach().numpy()\n",
    "tr_data = x_train.reshape(x_train.shape[0],28*28).cpu().detach().numpy()\n",
    "\n",
    "exp_vecs = []\n",
    "for i,net in enumerate(nets):\n",
    "    model = CNN_model_wrap(net,dev=device).predict_proba\n",
    "    v,y_pred = exp_point(point_exp,tr_data,model,f_names,c_names)\n",
    "    exp_vecs.append(v)\n",
    "    plt.figure(i)\n",
    "    plt.imshow(v.reshape(28,28))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = 0.5*np.ones((16,16))\n",
    "for i,vec1 in enumerate(exp_vecs):\n",
    "    for j,vec2 in enumerate(exp_vecs):\n",
    "        if i == j:\n",
    "            pass\n",
    "        else:\n",
    "            sim_matrix[i,j] = cos_sim(vec1,vec2)\n",
    "        \n",
    "plt.figure()\n",
    "plt.imshow(sim_matrix)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack each \n",
    "\n",
    "'''\n",
    "1. generate explanations for each data point (num_models x num_points)\n",
    "2. generate adv examples for each point (num_models x num_points)\n",
    "3. plot x = average similarity and y = transferability\n",
    "'''\n",
    "\n",
    "point_exps = x_test[0:20].cpu().detach().numpy()\n",
    "points_attack = x_test[0:20]\n",
    "points_attack = points_attack.reshape(points_attack.shape[0],1,28,28)\n",
    "labels = y_test[0:20]\n",
    "all_exps = []\n",
    "adv_examps = []\n",
    "for i,net in enumerate(nets):\n",
    "    adversary_LinfPGD = LinfPGDAttack(\n",
    "        net, loss_fn=nn.CrossEntropyLoss(reduction=\"sum\"), eps=0.15,\n",
    "        nb_iter=40, eps_iter=0.01, rand_init=True, clip_min=0.0, clip_max=1.0,\n",
    "        targeted=False)\n",
    "    pgd_advex = adversary_LinfPGD.perturb(points_attack)\n",
    "    adv_examps.append(pgd_advex.cpu().detach().numpy())\n",
    "    model = CNN_model_wrap(net,dev=device).predict_proba\n",
    "    exps = []\n",
    "    for point in point_exps:\n",
    "        v,y_pred = exp_point(point_exp,tr_data,model,f_names,c_names)\n",
    "        exps.append(v)\n",
    "    all_exps.append(exps)\n",
    "\n",
    "all_exps = np.array(all_exps)\n",
    "adv_examps = np.array(adv_examps)\n",
    "\n",
    "print(all_exps.shape)\n",
    "print(adv_examps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./all_explanationsCNN.npy',all_exps)\n",
    "np.save('./all_advexamplesCNN.npy',adv_examps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = []\n",
    "transf = []\n",
    "amnt_adv = []\n",
    "\n",
    "for i,(net1,exps1,advs1) in enumerate(zip(nets,all_exps,adv_examps)):\n",
    "    for j,(net2,exps2,advs2) in enumerate(zip(nets,all_exps,adv_examps)):\n",
    "        if i > j:\n",
    "            pass\n",
    "        else:\n",
    "            sim.append((1./exps1.shape[0])*norm(exps1-exps2,'fro'))\n",
    "            out1 = torch.argmax(net1(torch.from_numpy(advs1).to(device)),dim=1)\n",
    "            amnt_adv.append(1.-accuracy_score(out1.cpu().detach().numpy(),labels.cpu().detach().numpy()))\n",
    "            tr_net1 = torch.from_numpy(advs1).to(device)[out1 != labels]\n",
    "            tr_lbl = labels[out1 != labels]\n",
    "            out2 = torch.argmax(net2(tr_net1),dim=1)\n",
    "            transf.append(1.-accuracy_score(out2.cpu().detach().numpy(),tr_lbl.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,[5,5])\n",
    "plt.scatter(sim,transf,color='tab:blue',label='% transfer')\n",
    "plt.scatter(sim,amnt_adv,color='tab:red',label='% adv')\n",
    "plt.xlabel('explanation similarity')\n",
    "plt.ylabel('% adv')\n",
    "plt.legend()#loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for net1 in nets:\n",
    "    for net2 in nets:\n",
    "        generate adv examples for net1 (y1)\n",
    "        run them through net2 (y2)\n",
    "        generate exp1,exp2 explanations for each net1,net2\n",
    "        y1,y2,exp1,exp2\n",
    "        if y1,y2 both trick, take note of sim(exp1,exp2)\n",
    "        \n",
    "built histogram? other type of plot? \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
