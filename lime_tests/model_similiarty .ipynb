{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# general\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from numpy import dot \n",
    "# sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "# lime\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "# art\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.estimators.classification import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.fc_linears = nn.ModuleList()\n",
    "        for i in range(len(self.layers)-1):\n",
    "            self.fc_linears.append(nn.Linear(in_features=self.layers[i], out_features=self.layers[i+1]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i,l in enumerate(self.fc_linears):\n",
    "            in_dim = self.layers[i]\n",
    "            out_dim = self.layers[i+1]\n",
    "            btch_nrm = nn.BatchNorm1d(out_dim)\n",
    "            x = F.relu(btch_nrm(l(x.type(torch.float))))\n",
    "        return x\n",
    "    \n",
    "class model_wrap():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def predict_proba(self,x):\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        return softmax(self.model.model(Variable(torch.from_numpy(x)))).detach().numpy()#(Variable(torch.from_numpy(x)))) # took out model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def data(X,y,test_percent,rnd_st=0):\n",
    "    '''\n",
    "    returns train/test data\n",
    "    Args - \n",
    "        X: x data\n",
    "        y: y data\n",
    "        test_percent: percent of the data set to hold for testing\n",
    "        rnd_st: random state \n",
    "    Returns - \n",
    "        x_train: training data from X\n",
    "        y_train: training data from y\n",
    "        x_test: testing data from X\n",
    "        y_test: testing data from y\n",
    "    '''\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=test_percent, random_state=rnd_st)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def train_model(layers,X,y,rnd_st=0):\n",
    "    '''\n",
    "    builds a model from given network structure.\n",
    "    Args - \n",
    "        layers: tuple of hidden layer sizes \n",
    "        X: X data\n",
    "        y: y data\n",
    "        rnd_st: random state \n",
    "    Returns - \n",
    "        model: a trained sklearn model ready for training \n",
    "    '''\n",
    "    model = MLPClassifier(layers)\n",
    "    model.fit(X,y)\n",
    "    return model \n",
    "\n",
    "def train_model_torch(layers,X,y,rnd_st=0):\n",
    "    '''\n",
    "    builds a model from given network structure.\n",
    "    Args - \n",
    "        layers: tuple of hidden layer sizes \n",
    "        X: X data\n",
    "        y: y data\n",
    "        rnd_st: random state \n",
    "    Returns - \n",
    "        model: a trained sklearn model ready for training \n",
    "    '''\n",
    "    model = Net(layers)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    model_w = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=64,\n",
    "    nb_classes=10)\n",
    "    model_w.fit(X, y, batch_size=1000, nb_epochs=20)\n",
    "    return model_w\n",
    "\n",
    "def build_model_matrix(s,n,lyr_array,X,y):\n",
    "    '''\n",
    "    builds an sxn matrix where the i,j entry is a sklearn model. Each column has a different arcitecture, and each \n",
    "    row within a column as a different initial parameters initialization.\n",
    "    Args - \n",
    "        s: number of different model parameter initializations\n",
    "        n: number of different model arcitectures\n",
    "        lyr_array: array of layers for the networks (currently enter manually, plan on creating code to do this)\n",
    "            *note* n = len(lyr_array)\n",
    "        X: X training data\n",
    "        y: y training data\n",
    "    returns: sxn model matrix of trained sklearn models \n",
    "    '''\n",
    "    model_matrix = []\n",
    "    for i in range(s):\n",
    "        models_same_arc = []\n",
    "        for j in range(n):\n",
    "            model = train_model(lyr_array[j],X,y,rnd_st=j)\n",
    "            models_same_arc.append(model)\n",
    "        model_matrix.append(models_same_arc)\n",
    "    return np.array(model_matrix)\n",
    "\n",
    "def build_model_matrix_torch(s,n,lyr_array,X,y):\n",
    "    '''\n",
    "    builds an sxn matrix where the i,j entry is a sklearn model. Each column has a different arcitecture, and each \n",
    "    row within a column as a different initial parameters initialization.\n",
    "    Args - \n",
    "        s: number of different model parameter initializations\n",
    "        n: number of different model arcitectures\n",
    "        lyr_array: array of layers for the networks (currently enter manually, plan on creating code to do this)\n",
    "            *note* n = len(lyr_array)\n",
    "        X: X training data\n",
    "        y: y training data\n",
    "    returns: sxn model matrix of trained sklearn models \n",
    "    '''\n",
    "    model_matrix = []\n",
    "    for i in range(s):\n",
    "        models_same_arc = []\n",
    "        for j in range(n):\n",
    "            model = train_model_torch(lyr_array[j],X,y,rnd_st=j)\n",
    "            models_same_arc.append(model)\n",
    "        model_matrix.append(models_same_arc)\n",
    "    return np.array(model_matrix)\n",
    "\n",
    "def accurc_score(model,X,y):\n",
    "    '''\n",
    "    computes the accuracy score for a given model on the testing data\n",
    "    Args - \n",
    "        model: the classifier to test\n",
    "        X: X testing data\n",
    "        y: y testing data\n",
    "    Returns - \n",
    "        acc_sc: accuracy score \n",
    "    '''\n",
    "    acc_sc = accuracy_score(y, model.predict(X))\n",
    "    return acc_sc\n",
    "\n",
    "def accurc_score_torch(model,X,y):\n",
    "    '''\n",
    "    computes the accuracy score for a given model on the testing data\n",
    "    Args - \n",
    "        model: the classifier to test\n",
    "        X: X testing data\n",
    "        y: y testing data\n",
    "    Returns - \n",
    "        acc_sc: accuracy score \n",
    "    '''\n",
    "    pred = model.predict(X)\n",
    "    acc_sc = accuracy_score(y,[np.where(p==p.max())[0][0] for p in pred])\n",
    "    return acc_sc\n",
    "\n",
    "def accuracy_matrix(models,X,y):\n",
    "    '''\n",
    "    computes the model accuracy matrix, the i,j entry is the accuracy score of the i,j model\n",
    "    Args - \n",
    "        models: np ndarray of models to test\n",
    "        X: X testing data\n",
    "        y: y testing data\n",
    "    Returns - \n",
    "        acc_matrix: accuracy score matrix  \n",
    "    '''\n",
    "    s = models.shape[0]\n",
    "    n = models.shape[1]\n",
    "    acc_matrix = np.zeros((s,n))\n",
    "    for i in range(s):\n",
    "        for j in range(n):\n",
    "            acc_matrix[i,j] = accurc_score(models[i,j],X,y)\n",
    "    return acc_matrix \n",
    "\n",
    "def accuracy_matrix_torch(models,X,y):\n",
    "    '''\n",
    "    computes the model accuracy matrix, the i,j entry is the accuracy score of the i,j model\n",
    "    Args - \n",
    "        models: np ndarray of models to test\n",
    "        X: X testing data\n",
    "        y: y testing data\n",
    "    Returns - \n",
    "        acc_matrix: accuracy score matrix  \n",
    "    '''\n",
    "    s = models.shape[0]\n",
    "    n = models.shape[1]\n",
    "    acc_matrix = np.zeros((s,n))\n",
    "    for i in range(s):\n",
    "        for j in range(n):\n",
    "            acc_matrix[i,j] = accurc_score_torch(models[i,j],X,y)\n",
    "    return acc_matrix \n",
    "\n",
    "def make_exp_vec(exp):\n",
    "    \"\"\"\n",
    "    Takes a LIME explanation which is a dictionary (i, w(i)) where i is the feature id and w(i) is the weight \n",
    "    of the ith feature. With the explanation vector we generate, we can \n",
    "    Arg - \n",
    "        exp: LIME explanation\n",
    "    Returns - \n",
    "        v: explanation vector where v[i] = w(i)\n",
    "        y_pred: the prediction of the model\n",
    "    \"\"\"\n",
    "    k = list(exp.keys())[0]\n",
    "    l = exp[k]\n",
    "    v = np.zeros(len(l))\n",
    "    for (i,w) in l:\n",
    "        v[i] = w\n",
    "    y_pred = k\n",
    "    return v,y_pred\n",
    "\n",
    "def exp_point(point,X,model,f_names,c_names):\n",
    "    \"\"\"\n",
    "    The explanation vector for top label of a point in a certain data set.\n",
    "    Arg - \n",
    "        point: point to explain\n",
    "        X: data model was trained on\n",
    "        model: black box\n",
    "        f_names: names of features\n",
    "        c_names: names of classes\n",
    "    Returns - \n",
    "        v: explanation vector (see make_exp_vec())\n",
    "        y_pred: model prediction\n",
    "    \"\"\"\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(X, feature_names=f_names, class_names=c_names, discretize_continuous=False)\n",
    "    exp = explainer.explain_instance(point, model.predict_proba, num_features=len(point), top_labels=1)#, sampling_method='lhs')\n",
    "    v,y_pred = make_exp_vec(exp.local_exp)\n",
    "    return v, y_pred\n",
    "\n",
    "def exp_point_torch(point,X,model,f_names,c_names):\n",
    "    \"\"\"\n",
    "    The explanation vector for top label of a point in a certain data set.\n",
    "    Arg - \n",
    "        point: point to explain\n",
    "        X: data model was trained on\n",
    "        model: black box\n",
    "        f_names: names of features\n",
    "        c_names: names of classes\n",
    "    Returns - \n",
    "        v: explanation vector (see make_exp_vec())\n",
    "        y_pred: model prediction\n",
    "    \"\"\"\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(X, feature_names=f_names, class_names=c_names, discretize_continuous=False)\n",
    "    exp = explainer.explain_instance(point, model_wrap(model).predict_proba, num_features=len(point), top_labels=1)#, sampling_method='lhs')\n",
    "    v,y_pred = make_exp_vec(exp.local_exp)\n",
    "    return v, y_pred\n",
    "\n",
    "def similarity_matrix(models,X,point,f_names,c_names):\n",
    "    '''\n",
    "    computes a matrix where the i,j entry is the similarity of the i and j models \n",
    "    computed via cosine similarity of the explanation vectors \n",
    "    turns model matrix into array by extending along the columns (ie puts all the models with the same\n",
    "    arcitecture next to eachother)\n",
    "    Args - \n",
    "        models: matrix of models\n",
    "        X: X training data\n",
    "        point: x to explain (take from x_test)\n",
    "        f_names: feature names\n",
    "        c_names: class names\n",
    "    Returns - \n",
    "        sim_matrix: snxsn similarity matrix\n",
    "    '''\n",
    "    s = models.shape[0]\n",
    "    n = models.shape[1]\n",
    "    flat_models = models.flatten('F')   # reshape via F? \n",
    "    flat_sims = []\n",
    "    for m1 in flat_models:\n",
    "        for m2 in flat_models:\n",
    "            exp1,y1_pred = exp_point(point,X,m1,f_names,c_names)\n",
    "            exp2,y2_pred = exp_point(point,X,m2,f_names,c_names)\n",
    "            \n",
    "            if y1_pred == y2_pred:\n",
    "                flat_sims.append(np.dot(exp1,exp2)/(norm(exp1)*norm(exp2)))\n",
    "            else:\n",
    "                flat_sims.append(-2)\n",
    "    sim_matrix = np.reshape(np.array(flat_sims),(s*n,s*n),'F')   # reshape via F ?\n",
    "    return sim_matrix\n",
    "\n",
    "def similarity_matrix_torch(models,X,point,f_names,c_names):\n",
    "    '''\n",
    "    computes a matrix where the i,j entry is the similarity of the i and j models \n",
    "    computed via cosine similarity of the explanation vectors \n",
    "    turns model matrix into array by extending along the columns (ie puts all the models with the same\n",
    "    arcitecture next to eachother)\n",
    "    Args - \n",
    "        models: matrix of models\n",
    "        X: X training data\n",
    "        point: x to explain (take from x_test)\n",
    "        f_names: feature names\n",
    "        c_names: class names\n",
    "    Returns - \n",
    "        sim_matrix: snxsn similarity matrix\n",
    "    '''\n",
    "    s = models.shape[0]\n",
    "    n = models.shape[1]\n",
    "    flat_models = models.flatten('F')   # reshape via F? \n",
    "    flat_sims = []\n",
    "    for m1 in flat_models:\n",
    "        for m2 in flat_models:\n",
    "            exp1,y1_pred = exp_point_torch(point,X,m1,f_names,c_names)\n",
    "            exp2,y2_pred = exp_point_torch(point,X,m2,f_names,c_names)\n",
    "            \n",
    "            if y1_pred == y2_pred:\n",
    "                flat_sims.append(np.dot(exp1,exp2)/(norm(exp1)*norm(exp2)))\n",
    "            else:\n",
    "                flat_sims.append(1.25)\n",
    "    sim_matrix = np.reshape(np.array(flat_sims),(s*n,s*n),'F')   # reshape via F ?\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training data \n",
    "# digits = load_digits()\n",
    "# x_train, y_train, x_test, y_test = data(digits['data'],digits['target'],0.3,rnd_st=0)\n",
    "# x_names = np.arange(0,64)\n",
    "# y_names = digits['target_names']\n",
    "\n",
    "dataset = MNIST('.', train=True, download=False,transform=transforms.ToTensor())\n",
    "x_train = dataset.train_data.reshape(len(dataset.train_data),28*28).double()\n",
    "y_train = dataset.train_labels.double()\n",
    "x_test = dataset.test_data.reshape(len(dataset.test_data),28*28).double()\n",
    "y_test = dataset.test_labels.double()\n",
    "\n",
    "x_names = np.arange(0,28*28) \n",
    "y_names = ['0','1','2','3','4','5','6','7','8','9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create model matrix \n",
    "# model_matrix = build_model_matrix(4,3,[(64,128,256,128,32),(128,64,128,256,32),(64,96,64,32,16)],x_train,y_train)\n",
    "\n",
    "# # accuracy matrix\n",
    "# accuracy_matrix = accuracy_matrix(model_matrix,x_test,y_test)\n",
    "# plt.figure(1,[5,5])\n",
    "# plt.imshow(accuracy_matrix)\n",
    "# plt.colorbar()\n",
    "# plt.axis('off')\n",
    "# plt.title('model accuracy scores')\n",
    "# plt.show()\n",
    "\n",
    "# # similarity matrix\n",
    "# similarity_matrix = similarity_matrix(model_matrix,x_train,x_test[0],x_names,y_names)\n",
    "# plt.figure(2,[5,5])\n",
    "# plt.imshow(similarity_matrix)\n",
    "# plt.colorbar()\n",
    "# plt.axis('off')\n",
    "# plt.title('model similarity')\n",
    "# plt.show()\n",
    "\n",
    "'''\n",
    "# intuition as to how model sim matrix constructed \n",
    "def prod(val) :  \n",
    "    res = 1 \n",
    "    for ele in val:  \n",
    "        res *= ele  \n",
    "    return res \n",
    "\n",
    "matrix = np.array([['(0,0)','(0,1)'],['(1,0)','(1,1)'],['(2,0)','(2,1)']])\n",
    "m_flat = matrix.flatten('F')\n",
    "interactions = []\n",
    "for m1 in m_flat:\n",
    "    for m2 in m_flat:\n",
    "        interactions.append(m1+m2)\n",
    "interactions = np.array(interactions)\n",
    "s = prod(list(matrix.shape))\n",
    "np.reshape(interactions,(s,s),'F')[:,5]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create model matrix \n",
    "# Layers = [(64,32,16,12,10),\n",
    "#           (64,56,32,16,10),\n",
    "#           (64,96,32,16,10),\n",
    "#           (64,32,16,10),\n",
    "#           (64,56,10),\n",
    "#           (64,48,32,10),\n",
    "#           (64,48,32,10,8,6,10)]\n",
    "# model_matrix = build_model_matrix_torch(7,len(Layers),Layers,x_train,y_train)\n",
    "\n",
    "# # accuracy matrix\n",
    "# accuracy_matrix = accuracy_matrix_torch(model_matrix,x_test,y_test)\n",
    "# plt.figure(1,[5,5])\n",
    "# plt.imshow(accuracy_matrix)\n",
    "# plt.colorbar()\n",
    "# plt.axis('off')\n",
    "# plt.title('model accuracy scores')\n",
    "# plt.show()\n",
    "\n",
    "# # similarity matrix\n",
    "# similarity_matrix = similarity_matrix_torch(model_matrix,x_train,x_test[0],x_names,y_names)\n",
    "# plt.figure(2,[5,5])\n",
    "# plt.imshow(similarity_matrix)\n",
    "# plt.colorbar()\n",
    "# plt.axis('off')\n",
    "# plt.title('model similarity')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model matrix \n",
    "Layers = [(784,636,484,256,64,10),\n",
    "          (784,636,484,384,256,128,64,32,16,10),\n",
    "          (784,800,600,400,200,10),\n",
    "          (784,800,600,400,200,100,50,10)]\n",
    "model_matrix = build_model_matrix_torch(4,len(Layers),Layers,x_train,y_train)\n",
    "\n",
    "# accuracy matrix\n",
    "accuracy_matrix = accuracy_matrix_torch(model_matrix,x_test,y_test)\n",
    "plt.figure(1,[5,5])\n",
    "plt.imshow(accuracy_matrix)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title('model accuracy scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "similarity_matrix = similarity_matrix_torch(model_matrix,x_train.detach().numpy(),x_test[0].detach().numpy(),x_names,y_names)\n",
    "plt.figure(2,[5,5])\n",
    "plt.imshow(similarity_matrix)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title('model similarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adversarial example generation \n",
    "model_list = model_matrix.flatten()\n",
    "ind = np.random.choice(len(x_test), 250, replace=False)\n",
    "x_ = x_test[ind]\n",
    "y_ = y_test[ind]\n",
    "\n",
    "x_adv_exs = []\n",
    "adv_acc = []\n",
    "for model in model_list:\n",
    "    attack = FastGradientMethod(estimator=model, eps=3.)\n",
    "    x_adv = attack.generate(x=x_)\n",
    "    x_adv_exs.append(x_adv)\n",
    "    adv_acc.append(accuracy_score(np.argmax(model.predict(x_adv),axis=1),y_))\n",
    "\n",
    "x_adv_exs = np.array(x_adv_exs)\n",
    "adv_acc = np.array(adv_acc)\n",
    "print(adv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer = []\n",
    "for model in model_list:\n",
    "    adv_rates = []\n",
    "    for adv_ex in x_adv_exs:\n",
    "        adv_rates.append(accuracy_score(np.argmax(model.predict(adv_ex),axis=1),y_))\n",
    "    transfer.append(adv_rates)\n",
    "transfer = np.array(transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('transferability')\n",
    "plt.imshow(transfer)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the explanation vectors \"point\" in the direction of the adversarial example? \n",
    "model = model_list[0]\n",
    "ind = np.random.choice(len(x_test), 500, replace=False)\n",
    "x_ = x_test[ind]\n",
    "y_ = y_test[ind]\n",
    "\n",
    "#generate explanations\n",
    "exp_vecs = []\n",
    "preds = []\n",
    "for x in x_:\n",
    "    v, y_pred = exp_point_torch(x.detach().numpy(),x_test.detach().numpy(),model,x_names,y_names)\n",
    "    exp_vecs.append(v)\n",
    "    preds.append(y_pred)\n",
    "exp_vecs = np.array(exp_vecs)\n",
    "preds = np.array(preds)\n",
    "\n",
    "# generate attacks\n",
    "attack = FastGradientMethod(estimator=model, eps=3.)\n",
    "x_adv = attack.generate(x=x_)\n",
    "adv_pred = np.argmax(model.predict(x_adv),axis=1)\n",
    "adv_acc = accuracy_score(adv_pred,y_)\n",
    "print('model acc on adv example: ', adv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the pertubation\n",
    "deltas = []\n",
    "for x,xa in zip(x_,x_adv):\n",
    "    deltas.append(np.subtract(xa,x).detach().numpy())\n",
    "deltas = np.array(deltas)\n",
    "\n",
    "# select the ones which are adversarial examples\n",
    "adv_indx = []\n",
    "for i,(y_tr,y_adv) in enumerate(zip(y_,adv_pred)):\n",
    "    if y_tr == y_adv:\n",
    "        pass\n",
    "    elif y_tr != y_adv:\n",
    "        adv_indx.append(i)\n",
    "    else:\n",
    "        print('error')\n",
    "adv_indx = np.array(adv_indx)\n",
    "\n",
    "# compare cosine similarity on actual adv examples\n",
    "sims = []\n",
    "for exp,d in zip(exp_vecs[adv_indx],deltas[adv_indx]):\n",
    "    sims.append(dot(-1.*exp,d)/(norm(d)*norm(exp)))\n",
    "sims = np.array(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.hist(sims,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
