{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#####################\n",
    "# my files\n",
    "# target model\n",
    "#from net_ import target_net\n",
    "from net_conv import target_net\n",
    "# gan architectures\n",
    "import gans_archs\n",
    "# advgan training class\n",
    "from GAN_ import advGAN\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = 'cuda:0'\n",
    "else:  \n",
    "    dev = 'cpu'\n",
    "\n",
    "print('device: ', dev)\n",
    "\n",
    "# functions\n",
    "def transform_data(data_loader_obj):\n",
    "    ims = []\n",
    "    lls = []\n",
    "    for imgs,lbls in data_loader_obj:\n",
    "        for img,lbl in zip(imgs,lbls):\n",
    "            ims.append(img)\n",
    "            lls.append(lbl)\n",
    "    ims = torch.stack(ims)\n",
    "    lls = torch.stack(lls)\n",
    "    return ims,lls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain mnist data and process\n",
    "batch_size = 128\n",
    "num_of_classes = 10\n",
    "\n",
    "def get_indices(dataset,ind_array):\n",
    "    indices =  []\n",
    "    for i in range(len(dataset.targets)):\n",
    "        for ind in ind_array:\n",
    "            if dataset.targets[i] == ind:\n",
    "                indices.append(i)\n",
    "    return indices\n",
    "\n",
    "dataset = MNIST('.', train=True, download=False,transform=transforms.ToTensor())\n",
    "\n",
    "idx = get_indices(dataset, np.arange(num_of_classes))\n",
    "data_loader_rftarget = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "data_loader_target = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "data_loader_gan = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "data_loader_test = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "\n",
    "classes = np.arange(num_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target model\n",
    "n_estimators = 500\n",
    "ims_train,lls_train = transform_data(data_loader_rftarget)\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "#rf.fit(ims_train.reshape(len(ims_train),28*28).detach().numpy(),lls_train)\n",
    "# save the model\n",
    "PATH = './target_models/rf_model'+str(num_of_classes)+'classes'+'_nest'+str(n_estimators)+'.joblib'\n",
    "#dump(rf, PATH) \n",
    "# load the model\n",
    "rf = load(PATH)\n",
    "\n",
    "# test random forest accuracy\n",
    "ims_test,lls_test = transform_data(data_loader_gan)\n",
    "print('accuracy: ', accuracy_score(rf.predict(ims_test.reshape(len(ims_test),28*28).detach().numpy()),lls_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train distilled neural network on output from random forest\n",
    "net = target_net(num_of_classes).to(dev)\n",
    "criterion_tar = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "PATH = './target_models/conv_net_distilled_'+str(num_of_classes)+'classes_device-'+dev+'.pth'\n",
    "# train and and save the model\n",
    "net.train(data_loader_target, criterion_tar, optimizer, dev, master_model=rf.predict)\n",
    "torch.save(net.state_dict(), PATH)\n",
    "# load the model\n",
    "net = target_net(num_of_classes).to(dev)\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "print('model accuracy: ', net.accuracy(data_loader_gan,dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gen/disc\n",
    "gen = gans_archs.Generator2()\n",
    "disc = gans_archs.Discriminator2()\n",
    "\n",
    "# arguments for GAN training \n",
    "target_net, gen, disc,\n",
    "tar_criterion=nn.CrossEntropyLoss()\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "batch_size=128\n",
    "lr=0.00001\n",
    "device=dev\n",
    "display_step=500\n",
    "gen_arch='cov'\n",
    "###############################\n",
    "gen_arch_num=2\n",
    "disc_coeff=1850.\n",
    "hinge_coeff=50.\n",
    "adv_coeff=200.\n",
    "c=0.2\n",
    "gen_path_extra='distilledrf_genarch_'+str(gen_arch_num)\n",
    "shape=(1,28,28)\n",
    "num_of_classes=num_of_classes\n",
    "################################\n",
    "\n",
    "# initiate advgan\n",
    "advgan = advGAN(net.predict_proba,gen,disc,tar_criterion=tar_criterion,\n",
    "                criterion=criterion,n_epochs=n_epochs,\n",
    "                batch_size=batch_size,num_of_classes=num_of_classes,\n",
    "                lr=lr,disc_coeff=disc_coeff,hinge_coeff=hinge_coeff,\n",
    "                adv_coeff=adv_coeff,c=c,gen_path_extra=gen_path_extra,\n",
    "                device=device,display_step=display_step,shape=shape,gen_arch=gen_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# train the gan\n",
    "gen,disc = advgan.train(data_loader_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# test transferability from adv examples for the nn to the rf\n",
    "counter = 0.\n",
    "total_rf_clean = 0.\n",
    "total_nn_clean = 0.\n",
    "total_rf_adv = 0.\n",
    "total_nn_adv = 0.\n",
    "for data,label in DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx)):\n",
    "    rf_output_clean = rf.predict(data.reshape(len(data),28*28).detach().numpy())\n",
    "    nn_output_clean = torch.argmax(net(data.reshape(len(data),28*28)),dim=1)\n",
    "    # make adv example\n",
    "    pert = gen(data.reshape(len(data),28*28))\n",
    "    adv_img = data.reshape(len(data),28*28) + pert\n",
    "    rf_output_adv = rf.predict(adv_img.detach().numpy())\n",
    "    nn_output_adv = torch.argmax(net(adv_img),dim=1)\n",
    "    # calculate and return accuracy \n",
    "    total_rf_clean += accuracy_score(rf_output_clean,label)\n",
    "    total_nn_clean += accuracy_score(nn_output_clean,label)\n",
    "    total_rf_adv += accuracy_score(rf_output_adv,label)\n",
    "    total_nn_adv += accuracy_score(nn_output_adv,label)\n",
    "    counter += 1.\n",
    "print('rf accuracy (clean): ', total_rf_clean/counter)\n",
    "print('nn accuracy (clean): ', total_nn_clean/counter)\n",
    "print('% adv rf: ', 1.-total_rf_adv/counter)\n",
    "print('% adv nn: ', 1.-total_nn_adv/counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exml",
   "language": "python",
   "name": "exml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
