{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#####################\n",
    "# my files\n",
    "# target model\n",
    "from net_ import target_net\n",
    "#from net_conv import target_net\n",
    "# gan architectures\n",
    "import gans_archs\n",
    "# advgan training class\n",
    "from GAN_ import advGAN\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = 'cuda:0'\n",
    "else:  \n",
    "    dev = 'cpu'\n",
    "\n",
    "print('device: ', dev)\n",
    "\n",
    "# functions\n",
    "def transform_data(data_loader_obj):\n",
    "    ims = []\n",
    "    lls = []\n",
    "    for imgs,lbls in data_loader_obj:\n",
    "        for img,lbl in zip(imgs,lbls):\n",
    "            ims.append(img)\n",
    "            lls.append(lbl)\n",
    "    ims = torch.stack(ims)\n",
    "    lls = torch.stack(lls)\n",
    "    return ims,lls\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25):\n",
    "    image_tensor = image_tensor.reshape(image_tensor.shape[0],1,28,28).cpu().detach()\n",
    "    size = (1,28,28)\n",
    "    image_unflat = image_tensor.detach().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain mnist data and process\n",
    "batch_size = 128\n",
    "num_of_classes = 2\n",
    "\n",
    "def get_indices(dataset,ind_array):\n",
    "    indices =  []\n",
    "    for i in range(len(dataset.targets)):\n",
    "        for ind in ind_array:\n",
    "            if dataset.targets[i] == ind:\n",
    "                indices.append(i)\n",
    "    return indices\n",
    "\n",
    "dataset = MNIST('.', train=True, download=False,transform=transforms.ToTensor())\n",
    "\n",
    "idx = get_indices(dataset, np.arange(num_of_classes))\n",
    "data_loader_rftarget = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "data_loader_target = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "data_loader_gan = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "data_loader_test = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "\n",
    "classes = np.arange(num_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target model\n",
    "n_estimators = 500\n",
    "ims_train,lls_train = transform_data(data_loader_rftarget)\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "#rf.fit(ims_train.reshape(len(ims_train),28*28).detach().numpy(),lls_train)\n",
    "# save the model\n",
    "PATH = './target_models/rf_model'+str(num_of_classes)+'classes'+'_nest'+str(n_estimators)+'.joblib'\n",
    "#dump(rf, PATH) \n",
    "# load the model\n",
    "rf = load(PATH)\n",
    "\n",
    "# test random forest accuracy\n",
    "ims_test,lls_test = transform_data(data_loader_gan)\n",
    "print('accuracy: ', accuracy_score(rf.predict(ims_test.reshape(len(ims_test),28*28).detach().numpy()),lls_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train distilled neural network on output from random forest\n",
    "net = target_net(num_of_classes).to(dev)\n",
    "criterion_tar = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "path_disttar = './target_models/ff_net_distilled_'+str(num_of_classes)+'classes_device-'+dev+'.pth'\n",
    "# train and and save the model\n",
    "#net.train(data_loader_target, criterion_tar, optimizer, dev, master_model=rf.predict)\n",
    "#torch.save(net.state_dict(), path_disttar)\n",
    "# load the model\n",
    "net = target_net(num_of_classes).to(dev)\n",
    "net.load_state_dict(torch.load(path_disttar))\n",
    "\n",
    "print('model accuracy: ', net.accuracy(data_loader_gan,dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gen/disc\n",
    "gen = gans_archs.Generator1()\n",
    "disc = gans_archs.Discriminator1()\n",
    "\n",
    "# arguments for GAN training \n",
    "tar_criterion=nn.CrossEntropyLoss()\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "batch_size=128\n",
    "lr=0.00001\n",
    "device=dev\n",
    "display_step=500\n",
    "gen_arch='cov'\n",
    "###############################\n",
    "gen_arch_num=1\n",
    "disc_coeff=2150.\n",
    "hinge_coeff=150.\n",
    "adv_coeff=700.\n",
    "c=0.2\n",
    "gen_path_extra='distilledrf_genarch_'+str(gen_arch_num)\n",
    "shape=(1,28,28)\n",
    "num_of_classes=num_of_classes\n",
    "################################\n",
    "\n",
    "# things to investigate\n",
    "'''\n",
    "add noise vector in generator\n",
    "change to 0-1 loss ? \n",
    "'''\n",
    "\n",
    "# initiate advgan\n",
    "advgan = advGAN(net,gen,disc,tar_criterion=tar_criterion,\n",
    "                criterion=criterion,n_epochs=n_epochs,\n",
    "                batch_size=batch_size,num_of_classes=num_of_classes,\n",
    "                lr=lr,disc_coeff=disc_coeff,hinge_coeff=hinge_coeff,\n",
    "                adv_coeff=adv_coeff,c=c,gen_path_extra=gen_path_extra,\n",
    "                device=device,display_step=display_step,shape=shape,gen_arch=gen_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# train the gan\n",
    "gen,disc = advgan.train(data_loader_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the generator \n",
    "path = advgan.gen_path\n",
    "full_path = path[0:15] + '/models_keep' + path[15::]\n",
    "gen = advgan.load_gen(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test transferability from adv examples for the nn to the rf\n",
    "counter = 0.\n",
    "total_rf_clean = 0.\n",
    "total_nn_clean = 0.\n",
    "total_rf_adv = 0.\n",
    "total_nn_adv = 0.\n",
    "for data,label in DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx)):\n",
    "    rf_output_clean = rf.predict(data.reshape(len(data),28*28).cpu().detach().numpy())\n",
    "    nn_output_clean = torch.argmax(net(data.reshape(len(data),28*28).to(dev)),dim=1)\n",
    "    # make adv example\n",
    "    pert = gen(data.reshape(len(data),28*28).to(dev))\n",
    "    adv_img = (data.reshape(len(data),28*28).to(dev) + pert).to(dev)\n",
    "    rf_output_adv = rf.predict(adv_img.cpu().detach().numpy())\n",
    "    nn_output_adv = torch.argmax(net(adv_img.to(dev)),dim=1)\n",
    "    # calculate and return accuracy \n",
    "    total_rf_clean += accuracy_score(rf_output_clean,label.cpu().detach().numpy())\n",
    "    total_nn_clean += accuracy_score(nn_output_clean.cpu().detach().numpy(),label.cpu().detach().numpy())\n",
    "    total_rf_adv += accuracy_score(rf_output_adv,label.cpu().detach().numpy())\n",
    "    total_nn_adv += accuracy_score(nn_output_adv.cpu().detach().numpy(),label.cpu().detach().numpy())\n",
    "    counter += 1.\n",
    "print('rf accuracy (clean): ', total_rf_clean/counter)\n",
    "print('nn accuracy (clean): ', total_nn_clean/counter)\n",
    "print('% adv rf: ', 1.-total_rf_adv/counter)\n",
    "print('% adv nn: ', 1.-total_nn_adv/counter)\n",
    "\n",
    "show_tensor_images(adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a net w/o the train method (messes up art if it is there)\n",
    "from net_ import target_net\n",
    "del target_net.train\n",
    "net_art = target_net(num_of_classes)\n",
    "net_art.load_state_dict(torch.load(path_disttar))\n",
    "\n",
    "# data to attack\n",
    "ims_attack,actual_lables = transform_data(data_loader_test)\n",
    "ims_attack = ims_attack.reshape(ims_attack.shape[0],28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ART torch classifier model\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "classifier = PyTorchClassifier(\n",
    "    model=net_art,\n",
    "    clip_values=(0, 1),\n",
    "    loss=criterion_tar,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(28*28,),\n",
    "    nb_classes=num_of_classes)\n",
    "\n",
    "# transferability of FGM attack\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
    "x_fgm_adv = attack.generate(x=ims_attack)\n",
    "\n",
    "# model output\n",
    "rf_output_clean = rf.predict(ims_attack)\n",
    "nn_output_clean = torch.argmax(net_art(ims_attack.to(dev)),dim=1)\n",
    "rf_output_adv = rf.predict(x_fgm_adv)\n",
    "nn_output_adv = torch.argmax(net_art(torch.from_numpy(x_fgm_adv).to(dev)),dim=1)\n",
    "    \n",
    "# calculate and return accuracy \n",
    "acc_rf_clean = accuracy_score(rf_output_clean,actual_lables)\n",
    "acc_nn_clean = accuracy_score(nn_output_clean.cpu().detach().numpy(),actual_lables)\n",
    "acc_rf_adv = accuracy_score(rf_output_adv,actual_lables)\n",
    "acc_nn_adv = accuracy_score(nn_output_adv.cpu().detach().numpy(),actual_lables)\n",
    "\n",
    "print('rf accuracy (clean): ', acc_rf_clean)\n",
    "print('nn accuracy (clean): ', acc_nn_clean)\n",
    "print('% adv rf: ', 1.-acc_rf_adv)\n",
    "print('% adv nn: ', 1.-acc_nn_adv)\n",
    "show_tensor_images(torch.from_numpy(x_fgm_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ART torch classifier model\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import CarliniL2Method,CarliniLInfMethod\n",
    "classifier = PyTorchClassifier(\n",
    "    model=net_art,\n",
    "    clip_values=(0, 1),\n",
    "    loss=criterion_tar,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(28*28,),\n",
    "    nb_classes=num_of_classes)\n",
    "\n",
    "# transferability of CW attack\n",
    "attack = CarliniL2Method(classifier)\n",
    "CW_adv_img = attack.generate(x=ims_attack[0:100],y=((actual_lables+1)%2)[0:100])\n",
    "np.save('./target_models/CW_adv_img.npy',CW_adv_img)\n",
    "#CW_adv_img = np.load('./target_models/CW_adv_img.npy')\n",
    "\n",
    "# model output\n",
    "rf_output_clean = rf.predict(ims_attack[0:100])\n",
    "nn_output_clean = torch.argmax(net_art(ims_attack.to(dev)[0:100]),dim=1)\n",
    "rf_output_adv = rf.predict(CW_adv_img)\n",
    "nn_output_adv = torch.argmax(net_art(torch.from_numpy(CW_adv_img).to(dev)),dim=1)\n",
    "    \n",
    "# calculate and return accuracy \n",
    "acc_rf_clean = accuracy_score(rf_output_clean,actual_lables[0:100])\n",
    "acc_nn_clean = accuracy_score(nn_output_clean.cpu().detach().numpy(),actual_lables[0:100])\n",
    "acc_rf_adv = accuracy_score(rf_output_adv,actual_lables[0:100])\n",
    "acc_nn_adv = accuracy_score(nn_output_adv.cpu().detach().numpy(),actual_lables[0:100])\n",
    "\n",
    "print('rf accuracy (clean): ', acc_rf_clean)\n",
    "print('nn accuracy (clean): ', acc_nn_clean)\n",
    "print('% adv rf: ', 1.-acc_rf_adv)\n",
    "print('% adv nn: ', 1.-acc_nn_adv)\n",
    "show_tensor_images(torch.from_numpy(x_pgd_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing to noisy data \n",
    "imgs_dirty = ims_attack + 0.5*torch.rand(ims_attack.shape)\n",
    "\n",
    "# model output\n",
    "rf_output_clean = rf.predict(ims_attack)\n",
    "nn_output_clean = torch.argmax(net_art(ims_attack.to(dev)),dim=1)\n",
    "rf_output_adv = rf.predict(imgs_dirty.detach().cpu().numpy())\n",
    "nn_output_adv = torch.argmax(net_art(imgs_dirty.to(dev)),dim=1)\n",
    "    \n",
    "# calculate and return accuracy \n",
    "acc_rf_clean = accuracy_score(rf_output_clean,actual_lables)\n",
    "acc_nn_clean = accuracy_score(nn_output_clean.cpu().detach().numpy(),actual_lables)\n",
    "acc_rf_adv = accuracy_score(rf_output_adv,actual_lables)\n",
    "acc_nn_adv = accuracy_score(nn_output_adv.cpu().detach().numpy(),actual_lables)\n",
    "\n",
    "print('rf accuracy (clean): ', acc_rf_clean)\n",
    "print('nn accuracy (clean): ', acc_nn_clean)\n",
    "print('% adv rf: ', 1.-acc_rf_adv)\n",
    "print('% adv nn: ', 1.-acc_nn_adv)\n",
    "show_tensor_images(torch.from_numpy(x_fgm_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
