{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#####################\n",
    "# my files\n",
    "# target model\n",
    "from net_ import target_net\n",
    "#from net_conv import target_net\n",
    "# gan architectures\n",
    "import gans_archs\n",
    "# advgan training class\n",
    "from GAN_ import advGAN\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = 'cuda:0'\n",
    "else:  \n",
    "    dev = 'cpu'\n",
    "\n",
    "print('device: ', dev)\n",
    "\n",
    "# functions\n",
    "def transform_data(data_loader_obj):\n",
    "    ims = []\n",
    "    lls = []\n",
    "    for imgs,lbls in data_loader_obj:\n",
    "        for img,lbl in zip(imgs,lbls):\n",
    "            ims.append(img)\n",
    "            lls.append(lbl)\n",
    "    ims = torch.stack(ims)\n",
    "    lls = torch.stack(lls)\n",
    "    return ims,lls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain mnist data and process\n",
    "batch_size = 128\n",
    "num_of_classes = 10\n",
    "\n",
    "def get_indices(dataset,ind_array):\n",
    "    indices =  []\n",
    "    for i in range(len(dataset.targets)):\n",
    "        for ind in ind_array:\n",
    "            if dataset.targets[i] == ind:\n",
    "                indices.append(i)\n",
    "    return indices\n",
    "\n",
    "dataset = MNIST('.', train=True, download=False,transform=transforms.ToTensor())\n",
    "\n",
    "idx = get_indices(dataset, np.arange(num_of_classes))\n",
    "data_loader_target = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "data_loader_gan = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "data_loader_test = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "\n",
    "classes = np.arange(num_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target model\n",
    "n_estimators = 750\n",
    "ims_train,lls_train = transform_data(data_loader_target)\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "#rf.fit(ims_train.reshape(len(ims_train),28*28).detach().numpy(),lls_train)\n",
    "# save the model\n",
    "PATH = './target_models/rf_model'+str(num_of_classes)+'classes'+'_nest'+str(n_estimators)+'.joblib'\n",
    "#dump(rf, PATH) \n",
    "# load the model\n",
    "rf = load(PATH)\n",
    "\n",
    "# test random forest accuracy\n",
    "ims_test,lls_test = transform_data(data_loader_gan)\n",
    "print('accuracy: ', accuracy_score(rf.predict(ims_test.reshape(len(ims_test),28*28).detach().numpy()),lls_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gen/disc\n",
    "gen = gans_archs.Generator1()#include_noise=True,device=dev)\n",
    "disc = gans_archs.Discriminator1()\n",
    "\n",
    "# arguments for GAN training \n",
    "#target_net, gen, disc,\n",
    "tar_criterion=nn.CrossEntropyLoss()\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "batch_size=128\n",
    "lr=0.00001\n",
    "display_step=500\n",
    "gen_arch='cov'\n",
    "###############################\n",
    "gen_arch_num=1\n",
    "disc_coeff=42950.\n",
    "hinge_coeff=50.\n",
    "adv_coeff=900.\n",
    "c=0.2\n",
    "gen_path_extra='rftar_proba_noisevec_genarch_'+str(gen_arch_num)\n",
    "shape=(1,28,28)\n",
    "num_of_classes=num_of_classes\n",
    "################################\n",
    "\n",
    "# initiate advgan\n",
    "advgan = advGAN(rf.predict_proba,gen,disc,tar_criterion=tar_criterion,\n",
    "                criterion=criterion,n_epochs=n_epochs,\n",
    "                batch_size=batch_size,num_of_classes=num_of_classes,\n",
    "                lr=lr,disc_coeff=disc_coeff,hinge_coeff=hinge_coeff,\n",
    "                adv_coeff=adv_coeff,c=c,gen_path_extra=gen_path_extra,\n",
    "                device=dev,display_step=display_step,shape=shape,gen_arch=gen_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# train the gan\n",
    "gen,disc = advgan.train(data_loader_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "'''\n",
    "When not concatenated with a noise vector, the robustness of the adv examples dies off. Results are illusrated \n",
    "in the form (epoch, % wrong, avg. frob. norm)\n",
    "(5, 0.4, 4.4)\n",
    "(25, 0.0, 0.29)\n",
    "(40, 0.008, 0.15)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
