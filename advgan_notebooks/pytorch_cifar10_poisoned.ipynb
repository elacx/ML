{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10 # Training dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#####################\n",
    "# my files\n",
    "# target model\n",
    "from net_conv_cifar import target_net, BasicBlock\n",
    "# gan architectures\n",
    "import gans_archs\n",
    "# advgan training class\n",
    "from GAN_ import advGAN\n",
    "# poison \n",
    "from poison_ import poison_func1_cifar\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = 'cuda:0'\n",
    "else:  \n",
    "    dev = 'cpu'\n",
    "\n",
    "print('device: ', dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain cfar10 data and process\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "data_loader_target = torch.utils.data.DataLoader(trainset, batch_size=150,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "data_loader_gan = torch.utils.data.DataLoader(trainset, batch_size=150,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "testset = CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "data_loader_test = torch.utils.data.DataLoader(trainset, batch_size=75,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_of_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# target model, resnet model from \n",
    "# https://github.com/kuangliu/pytorch-cifar\n",
    "net = target_net(BasicBlock, [2, 2, 2, 2]).to(dev)\n",
    "criterion_tar = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "PATH = './target_models/basic_net_convolutional_CIFAR_device-'+dev+'.pth'\n",
    "# train and and save the model\n",
    "net.train(data_loader_target, criterion_tar, optimizer, dev, 25,poison=0.1)\n",
    "torch.save(net.state_dict(), PATH)\n",
    "# load the model\n",
    "net = target_net(BasicBlock, [2, 2, 2, 2]).to(dev)\n",
    "net.load_state_dict(torch.load(PATH),dev)\n",
    "\n",
    "print('model accuracy: ', net.accuracy(data_loader_test,dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gen/disc\n",
    "gen = gans_archs.Generator3()\n",
    "disc = gans_archs.Discriminator3()\n",
    "\n",
    "# arguments for GAN training \n",
    "target_net, gen, disc,\n",
    "tar_criterion=nn.CrossEntropyLoss()\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "batch_size=128\n",
    "lr=0.00001\n",
    "device=dev\n",
    "display_step=500\n",
    "gen_arch='cov'\n",
    "###############################\n",
    "gen_arch_num=3\n",
    "disc_coeff=1850.\n",
    "hinge_coeff=50.\n",
    "adv_coeff=200.\n",
    "c=0.2\n",
    "gen_path_extra='cifar10_genarch_'+str(gen_arch_num)\n",
    "shape=(1,28,28)\n",
    "num_of_classes=num_of_classes\n",
    "p = True\n",
    "################################\n",
    "\n",
    "# initiate advgan\n",
    "advgan = advGAN(net,gen,disc,tar_criterion=tar_criterion,\n",
    "                criterion=criterion,n_epochs=n_epochs,\n",
    "                batch_size=batch_size,num_of_classes=num_of_classes,\n",
    "                lr=lr,disc_coeff=disc_coeff,hinge_coeff=hinge_coeff,\n",
    "                adv_coeff=adv_coeff,c=c,gen_path_extra=gen_path_extra,\n",
    "                device=device,display_step=display_step,shape=shape,gen_arch=gen_arch,poison=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# train the gan\n",
    "gen,disc = advgan.train(data_loader_gan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
