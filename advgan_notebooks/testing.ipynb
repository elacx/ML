{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain mnist data and process\n",
    "batch_size = 128\n",
    "num_of_classes = 10\n",
    "\n",
    "def get_indices(dataset,ind_array):\n",
    "    indices =  []\n",
    "    for i in range(len(dataset.targets)):\n",
    "        for ind in ind_array:\n",
    "            if dataset.targets[i] == ind:\n",
    "                indices.append(i)\n",
    "    return indices\n",
    "\n",
    "dataset = MNIST('.', train=True, download=False,transform=transforms.ToTensor())\n",
    "idx = get_indices(dataset, np.arange(num_of_classes))\n",
    "data_loader_test = DataLoader(dataset, batch_size=batch_size, sampler = SubsetRandomSampler(idx))\n",
    "\n",
    "classes = np.arange(num_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for img,lbl in data_loader_test:\n",
    "    print(torch.min(img).detach(),torch.max(img).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7463)\n"
     ]
    }
   ],
   "source": [
    "fakepred = torch.rand(10,1)\n",
    "fake_label = torch.zeros_like(fakepred)\n",
    "lossF = criterion(fakepred,fake_label)\n",
    "\n",
    "realpred = torch.rand(10,1)\n",
    "real_label = torch.ones_like(realpred)\n",
    "lossR = criterion(realpred,real_label)\n",
    "\n",
    "disc_loss = 0.5*(lossF + lossR)\n",
    "print(disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6889)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.rand(10,1),torch.rand(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6931])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(torch.sigmoid(torch.zeros(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(fake_label,fake_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6391)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.rand(1000,5)\n",
    "tar = torch.from_numpy(np.random.randint(2, size=1000))\n",
    "tar_criterion(preds,tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = .2\n",
    "pert = torch.rand((3,1,4,4))\n",
    "t = torch.norm(torch.norm(pert,2,-1),2,-1) # could also do frobenius norm 'fro'\n",
    "C = torch.full(t.shape, c)\n",
    "diff = t-C\n",
    "hinge_loss = torch.mean( torch.max(diff,torch.zeros(diff.shape)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing to noisy data \n",
    "imgs_noisey = torch.rand(128,28*28) + 0.25*torch.rand(128,28*28)\n",
    "\n",
    "# model output\n",
    "rf_output_clean = torch.rand(128)\n",
    "nn_output_clean = torch.rand(128)\n",
    "rf_output_adv = torch.rand(128)\n",
    "nn_output_adv = torch.rand(128)\n",
    "    \n",
    "# # calculate and return accuracy \n",
    "# acc_rf_clean = accuracy_score(rf_output_clean,actual_lables)\n",
    "# acc_nn_clean = accuracy_score(nn_output_clean.cpu().detach().numpy(),actual_lables)\n",
    "# acc_rf_adv = accuracy_score(rf_output_adv,actual_lables)\n",
    "# acc_nn_adv = accuracy_score(nn_output_adv.cpu().detach().numpy(),actual_lables)\n",
    "\n",
    "# print('rf accuracy (clean): ', acc_rf_clean)\n",
    "# print('nn accuracy (clean): ', acc_nn_clean)\n",
    "# print('% adv rf: ', 1.-acc_rf_adv)\n",
    "# print('% adv nn: ', 1.-acc_nn_adv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4768, 0.5956, 0.1290, 0.2718, 0.5799, 0.1799, 0.4614, 0.6201, 0.3596,\n",
       "        0.7912, 0.9995, 0.4843, 0.5644, 0.9633, 0.3290, 0.3427, 0.6147, 0.6928,\n",
       "        0.9551, 0.0778, 0.9429, 0.4803, 0.6511, 0.7452, 0.2137, 0.3196, 0.1509,\n",
       "        0.0067, 0.5432, 0.0456, 0.7924, 0.4186, 0.8525, 0.5221, 0.4453, 0.5653,\n",
       "        0.2650, 0.4624, 0.2129, 0.1841, 0.2024, 0.7199, 0.9694, 0.9968, 0.5124,\n",
       "        0.7521, 0.7087, 0.5162, 0.7047, 0.9184, 0.3673, 0.0585, 0.3029, 0.9747,\n",
       "        0.3508, 0.5380, 0.8177, 0.5450, 0.4133, 0.1430, 0.0975, 0.8122, 0.4355,\n",
       "        0.2898, 0.8787, 0.0802, 0.0456, 0.5841, 0.3029, 0.2801, 0.5657, 0.1965,\n",
       "        0.8499, 0.5490, 0.4241, 0.8070, 0.6314, 0.9673, 0.6634, 0.8277, 0.8922,\n",
       "        0.2655, 0.5425, 0.5674, 0.3923, 0.1686, 0.3952, 0.3018, 0.0986, 0.2248,\n",
       "        0.7407, 0.3140, 0.7604, 0.2926, 0.2217, 0.8733, 0.0312, 0.7593, 0.5419,\n",
       "        0.8061, 0.0318, 0.2471, 0.9279, 0.9418, 0.5450, 0.6962, 0.9401, 0.8342,\n",
       "        0.4633, 0.0717, 0.2517, 0.2260, 0.6094, 0.3479, 0.4017, 0.9795, 0.4256,\n",
       "        0.4253, 0.3963, 0.3993, 0.9823, 0.5868, 0.9364, 0.7820, 0.0528, 0.8122,\n",
       "        0.8139, 0.5024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_output_adv[rf_output_clean != nn_output_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([20,30,15])\n",
    "preds = torch.from_numpy(np.array([1,0,1]))\n",
    "labels = torch.from_numpy(np.array([1,1,1]))\n",
    "\n",
    "X[preds != labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(sum(labels == preds).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4806, -0.9914,  0.1470])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(0,1,preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-cb697db5a0c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_image_classifier_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_image_classifier_kr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_image_classifier_pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tabular_classifier_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_tabular_classifier_kr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_tabular_classifier_pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_test_classifier_type_check_fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exml/lib/python3.7/site-packages/tests/attacks/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# SOFTWARE.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytest'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import logging\n",
    "import unittest\n",
    "#import keras\n",
    "#import keras.backend as k\n",
    "import numpy as np\n",
    "\n",
    "from art.attacks.evasion.carlini import CarliniL2Method, CarliniLInfMethod\n",
    "from art.estimators.classification.keras import KerasClassifier\n",
    "from art.estimators.estimator import BaseEstimator\n",
    "from art.estimators.classification.classifier import ClassGradientsMixin\n",
    "from art.utils import random_targets, to_categorical\n",
    "\n",
    "from tests.utils import TestBase, master_seed\n",
    "from tests.utils import get_image_classifier_tf, get_image_classifier_kr, get_image_classifier_pt\n",
    "from tests.utils import get_tabular_classifier_tf, get_tabular_classifier_kr, get_tabular_classifier_pt\n",
    "from tests.attacks.utils import backend_test_classifier_type_check_fail\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TestCarlini(TestBase):\n",
    "    \"\"\"\n",
    "    A unittest class for testing the Carlini L2 attack.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        super().setUpClass()\n",
    "\n",
    "        cls.n_train = 10\n",
    "        cls.n_test = 10\n",
    "        cls.x_train_mnist = cls.x_train_mnist[0 : cls.n_train]\n",
    "        cls.y_train_mnist = cls.y_train_mnist[0 : cls.n_train]\n",
    "        cls.x_test_mnist = cls.x_test_mnist[0 : cls.n_test]\n",
    "        cls.y_test_mnist = cls.y_test_mnist[0 : cls.n_test]\n",
    "\n",
    "    def setUp(self):\n",
    "        master_seed(seed=1234)\n",
    "        super().setUp()\n",
    "\n",
    "    def test_tensorflow_failure_attack_L2(self):\n",
    "        \"\"\"\n",
    "        Test the corner case when attack is failed.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x_test_original = self.x_test_mnist.copy()\n",
    "\n",
    "        # Build TensorFlowClassifier\n",
    "        tfc, sess = get_image_classifier_tf(from_logits=True)\n",
    "\n",
    "        # Failure attack\n",
    "        cl2m = CarliniL2Method(\n",
    "            classifier=tfc, targeted=True, max_iter=0, binary_search_steps=0, learning_rate=0, initial_const=1\n",
    "        )\n",
    "        params = {\"y\": random_targets(self.y_test_mnist, tfc.nb_classes)}\n",
    "        x_test_adv = cl2m.generate(self.x_test_mnist, **params)\n",
    "        self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "        self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "        np.testing.assert_array_almost_equal(self.x_test_mnist, x_test_adv, decimal=3)\n",
    "\n",
    "        # Check that x_test has not been modified by attack and classifier\n",
    "        self.assertAlmostEqual(float(np.max(np.abs(x_test_original - self.x_test_mnist))), 0.0, delta=0.00001)\n",
    "\n",
    "        # Clean-up session\n",
    "        if sess is not None:\n",
    "            sess.close()\n",
    "\n",
    "    def test_tensorflow_mnist_L2(self):\n",
    "        \"\"\"\n",
    "        First test with the TensorFlowClassifier.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x_test_original = self.x_test_mnist.copy()\n",
    "\n",
    "        # Build TensorFlowClassifier\n",
    "        tfc, sess = get_image_classifier_tf(from_logits=True)\n",
    "\n",
    "        # First attack\n",
    "        cl2m = CarliniL2Method(classifier=tfc, targeted=True, max_iter=10)\n",
    "        params = {\"y\": random_targets(self.y_test_mnist, tfc.nb_classes)}\n",
    "        x_test_adv = cl2m.generate(self.x_test_mnist, **params)\n",
    "        self.assertFalse((self.x_test_mnist == x_test_adv).all())\n",
    "        self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "        self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "        target = np.argmax(params[\"y\"], axis=1)\n",
    "        y_pred_adv = np.argmax(tfc.predict(x_test_adv), axis=1)\n",
    "        logger.debug(\"CW2 Target: %s\", target)\n",
    "        logger.debug(\"CW2 Actual: %s\", y_pred_adv)\n",
    "        logger.info(\"CW2 Success Rate: %.2f\", (np.sum(target == y_pred_adv) / float(len(target))))\n",
    "        self.assertTrue((target == y_pred_adv).any())\n",
    "\n",
    "        # Second attack, no batching\n",
    "        cl2m = CarliniL2Method(classifier=tfc, targeted=False, max_iter=10, batch_size=1)\n",
    "        x_test_adv = cl2m.generate(self.x_test_mnist)\n",
    "        self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "        self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "        target = np.argmax(params[\"y\"], axis=1)\n",
    "        y_pred_adv = np.argmax(tfc.predict(x_test_adv), axis=1)\n",
    "        logger.debug(\"CW2 Target: %s\", target)\n",
    "        logger.debug(\"CW2 Actual: %s\", y_pred_adv)\n",
    "        logger.info(\"CW2 Success Rate: %.2f\", (np.sum(target == y_pred_adv) / float(len(target))))\n",
    "        self.assertTrue((target != y_pred_adv).any())\n",
    "\n",
    "        # Check that x_test has not been modified by attack and classifier\n",
    "        self.assertAlmostEqual(float(np.max(np.abs(x_test_original - self.x_test_mnist))), 0.0, delta=0.00001)\n",
    "\n",
    "        # Clean-up session\n",
    "        if sess is not None:\n",
    "            sess.close()\n",
    "\n",
    "    # @unittest.skipIf(\n",
    "    #     not (int(keras.__version__.split(\".\")[0]) == 2 and int(keras.__version__.split(\".\")[1]) >= 3),\n",
    "    #     reason=\"Minimal version of Keras or TensorFlow required.\",\n",
    "    # )\n",
    "    # def test_keras_mnist_L2(self):\n",
    "    #     \"\"\"\n",
    "    #     Second test with the KerasClassifier.\n",
    "    #     :return:\n",
    "    #     \"\"\"\n",
    "    #     x_test_original = self.x_test_mnist.copy()\n",
    "    #\n",
    "    #     # Build KerasClassifier\n",
    "    #     krc = get_image_classifier_kr(from_logits=True)\n",
    "    #\n",
    "    #     # First attack\n",
    "    #     cl2m = CarliniL2Method(classifier=krc, targeted=True, max_iter=10)\n",
    "    #     y_target = [6, 6, 7, 4, 9, 7, 9, 0, 1, 0]\n",
    "    #     x_test_adv = cl2m.generate(self.x_test_mnist, y=to_categorical(y_target, nb_classes=10))\n",
    "    #     self.assertFalse((self.x_test_mnist == x_test_adv).all())\n",
    "    #     self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "    #     self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "    #     y_pred_adv = np.argmax(krc.predict(x_test_adv), axis=1)\n",
    "    #     logger.debug(\"CW2 Target: %s\", y_target)\n",
    "    #     logger.debug(\"CW2 Actual: %s\", y_pred_adv)\n",
    "    #     logger.info(\"CW2 Success Rate: %.2f\", (np.sum(y_target == y_pred_adv) / float(len(y_target))))\n",
    "    #     self.assertTrue((y_target == y_pred_adv).any())\n",
    "    #\n",
    "    #     # Second attack\n",
    "    #     cl2m = CarliniL2Method(classifier=krc, targeted=False, max_iter=10)\n",
    "    #     x_test_adv = cl2m.generate(self.x_test_mnist)\n",
    "    #     self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "    #     self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "    #     y_pred_adv = np.argmax(krc.predict(x_test_adv), axis=1)\n",
    "    #     logger.debug(\"CW2 Target: %s\", y_target)\n",
    "    #     logger.debug(\"CW2 Actual: %s\", y_pred_adv)\n",
    "    #     logger.info(\"CW2 Success Rate: %.2f\", (np.sum(y_target != y_pred_adv) / float(len(y_target))))\n",
    "    #     self.assertTrue((y_target != y_pred_adv).any())\n",
    "    #\n",
    "    #     # Check that x_test has not been modified by attack and classifier\n",
    "    #     self.assertAlmostEqual(float(np.max(np.abs(x_test_original - self.x_test_mnist))), 0.0, delta=0.00001)\n",
    "    #\n",
    "    #     # Clean-up\n",
    "    #     k.clear_session()\n",
    "    #\n",
    "    # def test_pytorch_mnist_L2(self):\n",
    "    #     \"\"\"\n",
    "    #     Third test with the PyTorchClassifier.\n",
    "    #     :return:\n",
    "    #     \"\"\"\n",
    "    #     x_test = np.reshape(self.x_test_mnist, (self.x_test_mnist.shape[0], 1, 28, 28)).astype(np.float32)\n",
    "    #     x_test_original = x_test.copy()\n",
    "    #\n",
    "    #     # Build PyTorchClassifier\n",
    "    #     ptc = get_image_classifier_pt(from_logits=True)\n",
    "    #\n",
    "    #     # First attack\n",
    "    #     cl2m = CarliniL2Method(classifier=ptc, targeted=True, max_iter=10)\n",
    "    #     params = {\"y\": random_targets(self.y_test_mnist, ptc.nb_classes)}\n",
    "    #     x_test_adv = cl2m.generate(x_test, **params)\n",
    "    #     self.assertFalse((x_test == x_test_adv).all())\n",
    "    #     self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "    #     self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "    #     target = np.argmax(params[\"y\"], axis=1)\n",
    "    #     y_pred_adv = np.argmax(ptc.predict(x_test_adv), axis=1)\n",
    "    #     self.assertTrue((target == y_pred_adv).any())\n",
    "    #     logger.info(\"CW2 Success Rate: %.2f\", (sum(target == y_pred_adv) / float(len(target))))\n",
    "    #\n",
    "    #     # Second attack\n",
    "    #     cl2m = CarliniL2Method(classifier=ptc, targeted=False, max_iter=10)\n",
    "    #     x_test_adv = cl2m.generate(x_test)\n",
    "    #     self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "    #     self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "    #     target = np.argmax(params[\"y\"], axis=1)\n",
    "    #     y_pred_adv = np.argmax(ptc.predict(x_test_adv), axis=1)\n",
    "    #     self.assertTrue((target != y_pred_adv).any())\n",
    "    #     logger.info(\"CW2 Success Rate: %.2f\", (sum(target != y_pred_adv) / float(len(target))))\n",
    "    #\n",
    "    #     # Check that x_test has not been modified by attack and classifier\n",
    "    #     self.assertAlmostEqual(float(np.max(np.abs(x_test_original - x_test))), 0.0, delta=0.00001)\n",
    "\n",
    "    def test_classifier_type_check_fail_L2(self):\n",
    "        backend_test_classifier_type_check_fail(CarliniL2Method, [BaseEstimator, ClassGradientsMixin])\n",
    "\n",
    "    # def test_keras_iris_clipped_L2(self):\n",
    "    #     classifier = get_tabular_classifier_kr()\n",
    "    #     attack = CarliniL2Method(classifier, targeted=False, max_iter=10)\n",
    "    #     x_test_adv = attack.generate(self.x_test_iris)\n",
    "    #     self.assertFalse((self.x_test_iris == x_test_adv).all())\n",
    "    #     self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "    #     self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "    #\n",
    "    #     predictions_adv = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    #     self.assertFalse((np.argmax(self.y_test_iris, axis=1) == predictions_adv).all())\n",
    "    #     accuracy = np.sum(predictions_adv == np.argmax(self.y_test_iris, axis=1)) / self.y_test_iris.shape[0]\n",
    "    #     logger.info(\"Accuracy on Iris with C&W adversarial examples: %.2f%%\", (accuracy * 100))\n",
    "    #\n",
    "    # def test_keras_iris_unbounded_L2(self):\n",
    "    #     classifier = get_tabular_classifier_kr()\n",
    "    #\n",
    "    #     # Recreate a classifier without clip values\n",
    "    #     classifier = KerasClassifier(model=classifier._model, use_logits=False, channels_first=True)\n",
    "    #     attack = CarliniL2Method(classifier, targeted=False, max_iter=10)\n",
    "    #     x_test_adv = attack.generate(self.x_test_iris)\n",
    "    #     self.assertFalse((self.x_test_iris == x_test_adv).all())\n",
    "    #\n",
    "    #     predictions_adv = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    #     self.assertFalse((np.argmax(self.y_test_iris, axis=1) == predictions_adv).all())\n",
    "    #     accuracy = np.sum(predictions_adv == np.argmax(self.y_test_iris, axis=1)) / self.y_test_iris.shape[0]\n",
    "    #     logger.info(\"Accuracy on Iris with C&W adversarial examples: %.2f%%\", (accuracy * 100))\n",
    "\n",
    "    # def test_tensorflow_iris_L2(self):\n",
    "    #     classifier, _ = get_tabular_classifier_tf()\n",
    "    #\n",
    "    #     # Test untargeted attack\n",
    "    #     attack = CarliniL2Method(classifier, targeted=False, max_iter=10)\n",
    "    #     x_test_adv = attack.generate(self.x_test_iris)\n",
    "    #     self.assertFalse((self.x_test_iris == x_test_adv).all())\n",
    "    #     self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "    #     self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "    #\n",
    "    #     predictions_adv = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    #     self.assertFalse((np.argmax(self.y_test_iris, axis=1) == predictions_adv).all())\n",
    "    #     accuracy = np.sum(predictions_adv == np.argmax(self.y_test_iris, axis=1)) / self.y_test_iris.shape[0]\n",
    "    #     logger.info(\"Accuracy on Iris with C&W adversarial examples: %.2f%%\", (accuracy * 100))\n",
    "    #\n",
    "    #     # Test targeted attack\n",
    "    #     targets = random_targets(self.y_test_iris, nb_classes=3)\n",
    "    #     attack = CarliniL2Method(classifier, targeted=True, max_iter=10)\n",
    "    #     x_test_adv = attack.generate(self.x_test_iris, **{\"y\": targets})\n",
    "    #     self.assertFalse((self.x_test_iris == x_test_adv).all())\n",
    "    #     self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "    #     self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "    #\n",
    "    #     predictions_adv = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    #     self.assertTrue((np.argmax(targets, axis=1) == predictions_adv).any())\n",
    "    #     accuracy = np.sum(predictions_adv == np.argmax(targets, axis=1)) / self.y_test_iris.shape[0]\n",
    "    #     logger.info(\"Success rate of targeted C&W on Iris: %.2f%%\", (accuracy * 100))\n",
    "\n",
    "    # def test_pytorch_iris_L2(self):\n",
    "    #     classifier = get_tabular_classifier_pt()\n",
    "    #     attack = CarliniL2Method(classifier, targeted=False, max_iter=10)\n",
    "    #     x_test_adv = attack.generate(self.x_test_iris)\n",
    "    #     self.assertFalse((self.x_test_iris == x_test_adv).all())\n",
    "    #     self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "    #     self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "    #\n",
    "    #     predictions_adv = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    #     self.assertFalse((np.argmax(self.y_test_iris, axis=1) == predictions_adv).all())\n",
    "    #     accuracy = np.sum(predictions_adv == np.argmax(self.y_test_iris, axis=1)) / self.y_test_iris.shape[0]\n",
    "    #     logger.info(\"Accuracy on Iris with C&W adversarial examples: %.2f%%\", (accuracy * 100))\n",
    "\n",
    "    # def test_scikitlearn_L2(self):\n",
    "    #     from sklearn.linear_model import LogisticRegression\n",
    "    #     from sklearn.svm import SVC, LinearSVC\n",
    "    #\n",
    "    #     from art.estimators.classification.scikitlearn import SklearnClassifier\n",
    "    #\n",
    "    #     scikitlearn_test_cases = [\n",
    "    #         LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n",
    "    #         SVC(gamma=\"auto\"),\n",
    "    #         LinearSVC(),\n",
    "    #     ]\n",
    "    #\n",
    "    #     x_test_original = self.x_test_iris.copy()\n",
    "    #\n",
    "    #     for model in scikitlearn_test_cases:\n",
    "    #         classifier = SklearnClassifier(model=model, clip_values=(0, 1))\n",
    "    #         classifier.fit(x=self.x_test_iris, y=self.y_test_iris)\n",
    "    #\n",
    "    #         # Test untargeted attack\n",
    "    #         attack = CarliniL2Method(classifier, targeted=False, max_iter=2)\n",
    "    #         x_test_adv = attack.generate(self.x_test_iris)\n",
    "    #         self.assertFalse((self.x_test_iris == x_test_adv).all())\n",
    "    #         self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "    #         self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "    #\n",
    "    #         predictions_adv = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    #         self.assertFalse((np.argmax(self.y_test_iris, axis=1) == predictions_adv).all())\n",
    "    #         accuracy = np.sum(predictions_adv == np.argmax(self.y_test_iris, axis=1)) / self.y_test_iris.shape[0]\n",
    "    #         logger.info(\n",
    "    #             \"Accuracy of \" + classifier.__class__.__name__ + \" on Iris with C&W adversarial examples: \" \"%.2f%%\",\n",
    "    #             (accuracy * 100),\n",
    "    #         )\n",
    "    #\n",
    "    #         # Test targeted attack\n",
    "    #         targets = random_targets(self.y_test_iris, nb_classes=3)\n",
    "    #         attack = CarliniL2Method(classifier, targeted=True, max_iter=2)\n",
    "    #         x_test_adv = attack.generate(self.x_test_iris, **{\"y\": targets})\n",
    "    #         self.assertFalse((self.x_test_iris == x_test_adv).all())\n",
    "    #         self.assertLessEqual(np.amax(x_test_adv), 1.0)\n",
    "    #         self.assertGreaterEqual(np.amin(x_test_adv), 0.0)\n",
    "    #\n",
    "    #         predictions_adv = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    #         self.assertTrue((np.argmax(targets, axis=1) == predictions_adv).any())\n",
    "    #         accuracy = np.sum(predictions_adv == np.argmax(targets, axis=1)) / self.y_test_iris.shape[0]\n",
    "    #         logger.info(\n",
    "    #             \"Success rate of \" + classifier.__class__.__name__ + \" on targeted C&W on Iris: %.2f%%\",\n",
    "    #             (accuracy * 100),\n",
    "    #         )\n",
    "    #\n",
    "    #         # Check that x_test has not been modified by attack and classifier\n",
    "    #         self.assertAlmostEqual(float(np.max(np.abs(x_test_original - self.x_test_iris))), 0.0, delta=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
